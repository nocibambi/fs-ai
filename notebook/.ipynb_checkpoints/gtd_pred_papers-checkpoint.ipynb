{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "bb3da7ac967701e592eb0f7265fc0362e7de8a58"
   },
   "source": [
    "# Global terrorist database (GTD): predicting perpetrator groups"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "bd379d2e8147c979bff06afac521d02f1e02776f"
   },
   "source": [
    "## Problem description\n",
    "\"Use attack type, weapons used, description of the attack, etc. to build a model that can predict what group may have been responsible for an incident.\"\n",
    "\n",
    "## What is the problem?\n",
    "### Informal description\n",
    "We have data about terrorist attacks but we do now know who commited many of them. Our model should tell us who might be behind a new incident.\n",
    "\n",
    "### Formal description\n",
    "* Experience: Data about previous terrorist attacks.\n",
    "* Task: Predict which terrorist group might have been responsible for a new terrorist attacks.\n",
    "* Performance (baseline): The ratio of correctly predicted terrorist groups.\n",
    "\n",
    "### Assumptions\n",
    "* There are clearly defined groups behind the indicent.\n",
    "* Terrorist groups have a robust and consistent method which does not change significantly.\n",
    "* Terrorists approach \"terror problems\" similarly across groups, regions and time periods and therefore the patterns of some terrorist acts can help us to explain others or predict future ones.\n",
    "* Particular definition of terrorism (see appendixes)\n",
    "* The information sources and the information itself are valid\n",
    "\n",
    "### Similar problems\n",
    "Domain similarity: Other violent but non-terrorist acts\n",
    "\n",
    "## Why does the problem needs to be solved?\n",
    "### Motivation\n",
    "* Violent acts, like terrorism are wrong and should be stopped.\n",
    "* Better understanding terrorism might help us to also understand the motivation of the perpetrators and the broader circumstances causing them.\n",
    "* Ideally, we would be able to identify terrorist groups--even if they do not have any incident history in the database yet--which are planning an attact, their location, time and other specifics. We cannot do this based only on this dataset\n",
    "\n",
    "### Possible benefits\n",
    "* Having a better picture of the working of terrorist groups\n",
    "* Identify common patterns among terrorist acts and their perpetrators\n",
    "\n",
    "### Solution use\n",
    "* We can estimate better unknown past and future perpetrators.\n",
    "* Predict and prevent future events from happening.\n",
    "* Identify organizing principles behind terrorist acts and groups.\n",
    "\n",
    "## How would I solve the problem without machine learning?\n",
    "* Ethnographic approach: Interviewing perpetartors and their peers to gain knowledge about the story of their terrorist projects. What were their motivations, what were their aims, what circumstances did they have to follow, what practicalities did they need to attend?\n",
    "* Macrosociological approach: Examining the actual socio-economic patterns within the region preceding the terrorist acts and the material-technological circumstances with which the perpetrators needed to work with.\n",
    "\n",
    "# The Data\n",
    "The project examines the following dataset:\n",
    "> National Consortium for the Study of Terrorism and Responses to Terrorism (START). (2016). Global Terrorism Database [Data file]. Retrieved from https://www.start.umd.edu/gtd\n",
    "\n",
    "Data is missing for 1993.\n",
    "```python\n",
    "gtd.iyear.value_counts().sort_index()\n",
    "```\n",
    "Nonetheless, these are also available in a separate file.\n",
    "\n",
    "## GTD history timeline\n",
    "* 2001 University of Mariland gains data from Pinkerton about terrorism events from 1970 to 1997 (GTD1)\n",
    "* 2005 Digitization: corrections and adding information\n",
    "* April 2006 Funding to extend the data beyond 1997 through 2007 from archival sources and with a different concept of terrorism (GTD2)\n",
    "* 2008 data collection is finished, applying the new inclusion criteria also on the previous data\n",
    "* Spring of 2008- Spring of 2012: ISVG collects data betwen April 2008 - October 2011. This is integrated and the existing data is improved.\n",
    "* 2012 - Data starting with November 2011 is conducted by START,\n",
    "    - \"As a result of these improvements, **a direct comparison between 2011 and 2012 data likely overstates the increase in total attacks and fatalities** worldwide during this time period.\"\n",
    "    \n",
    "in 2014, [other researchers raised issues](https://www.washingtonpost.com/news/monkey-cage/wp/2014/08/11/how-to-fix-the-flaws-in-the-global-terrorism-database-and-why-it-matters/?noredirect=on) about the GTD's failure to make explicit its temporal differences. As of the time of access, the dataset description contains the following warning:\n",
    "\n",
    "> Users should note that differences in levels of attacks before and after January 1, 1998, before and after April 1, 2008, and before and after January 1, 2012 may be at least partially explained by differences in data collection\n",
    "\n",
    "## Further specs\n",
    "- Cases when the **\"coder noted some uncertainty whether an incident meets all of the criteria for inclusion (\"Doubt Terrorism Proper,\")\"**\n",
    "- The GTD includes failed attacs, but does not include foiled or failed plots and violent threats where no action were taken.\n",
    "- No state terrorims is included.\n",
    "- Sources range from well-known international news agencies to English translations of local papers written in numerous foreign languages.\n",
    "- Prior to 2012, identifying a yearâ€™s worth of terrorist incidents for inclusion in the GTD typically involved the use of approximately 300 unique news sources. By comparison, the 2012 update is based on a pool of over 1500 unique news sources.\n",
    "\n",
    "## Criteria for terrorism\n",
    "Three main criteria of terrorism\n",
    "- Intentional\n",
    "- Entails violence (against property/people)\n",
    "- Sub-national actor\n",
    "\n",
    "In addition, at least two of the following:\n",
    "- Provided some social goal (i.e. not only for profit)\n",
    "- Intention to convey message to the broader public\n",
    "- Outside humanitarian law"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "422226c2f7661c3441f853bc9c1545b1187ce595"
   },
   "source": [
    "## Similar works"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "31bf5c7dbcfedc0fcba7fafa72af1f27086618c1"
   },
   "source": [
    "There are a number of publicly available papers describing machine learning projects with the GTD. A few of them aims to predict perpetrator groups, most of them exclusively focusing on incidents in India. They are somehow built upon each other, so I reviewed closely the two most recent ones. One paper used 'Factor Analysis of Mixed Data' to select attributes for the model, imputed missing values, and used the data between 1990 and 2014 to predict perpetrators of the 2015 incidents. It reported a 73.2% accuracy with SVM <a id='1'> [[1]](#f1) </a>. Another one used data from 1970 and 2015 and--after some feature engineering, cleaning and rebalancing--it used C4.5 (or J48 in WEKA) to correctly classify 98.7936% of the instances with 0.988 F-measure and 0.998 ROC AUC <a id='2'> [[2]](#f2) </a>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "83836c143f355975927e87794ec4623269ecaca7"
   },
   "source": [
    "## Importing libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "036573d721c9a4b43850b3944165a1a1ebc03a96"
   },
   "source": [
    "## Fundamentals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_uuid": "c7f324db07bccfdbfd5c2f0022d31644e0ca7f4c",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "aa7b376e9a37065ae0b520e8955d5fec867d20d0"
   },
   "source": [
    "## EDA and preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_uuid": "e3db1d2dd0e97a9f9b86a3815af976a4fcaec092"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/andras/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import Normalizer, LabelEncoder\n",
    "from sklearn.ensemble import IsolationForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_uuid": "ba9b9da6e965e0311c357141b96b6c63608636d4"
   },
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "3b0c71acff1f801439272bd69d640a99601033c4"
   },
   "source": [
    "## Cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_uuid": "180fa7c8896feba5c6381cb2fd378cff5b96b023",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score, cross_validate, StratifiedKFold, StratifiedShuffleSplit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "9a73192d0be85a86a0ebd3ee0caf51dc854eb98d"
   },
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_uuid": "7f9e91269e4cc16d9a946d9770601127d8c2c138",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "95d3b74d5b7be112f3383dd7f32a252c85c59028"
   },
   "source": [
    "## Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_uuid": "3bbbc2e9a6fa8c5422a1acad20c2e1faaa21c843"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "3ba62c1eefd97e81969091a3b7a978285f09b7f9"
   },
   "source": [
    "## Memory management\n",
    "### Setting the temp folder\n",
    "This is required for \"jobs=-1\" to work on Kaggle at some cases (see https://www.kaggle.com/getting-started/45288#292143)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_uuid": "d85a1e3f02039ff73e726b555f34e42beac11d1c",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: JOBLIB_TEMP_FOLDER=/tmp\n"
     ]
    }
   ],
   "source": [
    "%env JOBLIB_TEMP_FOLDER=/tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_uuid": "501699cf01c63eca9d29d0f84e878d94cee9d5cc"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/andras/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2785: DtypeWarning: Columns (4,6,31,33,53,61,62,63,76,79,90,92,94,96,114,115,121) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "# Instead of the excel from their homepage, I use the csv version they uploaded to Kaggle\n",
    "#gtd = pd.read_excel(\"globalterrorismdb_0617dist.xlsx\")\n",
    "gtd = pd.read_csv(\"../input/globalterrorismdb_0617dist.csv\", encoding='ISO-8859-1')\n",
    "gtd = gtd.sample(frac=0.1, random_state=4721)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "eda43db2a7983526a0e0cf1bf9822e679cf4ed11"
   },
   "source": [
    "# <a id='f1'>[[1]](#1)</a> Terrorism Analytics: Learning to Predict the Perpetrator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "2fe1c802a92237df6d49d0703cfa4fe58f99a2d7"
   },
   "source": [
    "D. Talreja, J. Nagaraj, N. J. Varsha and K. Mahesh, \"Terrorism analytics: Learning to predict the perpetrator,\" 2017 International Conference on Advances in Computing, Communications and Informatics (ICACCI), Udupi, 2017, pp. 1723-1726. doi: 10.1109/ICACCI.2017.8126092"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "5cc98fe8930b6e4c0f18cba033a4faf4492f75a8"
   },
   "source": [
    "Because the authors trained their model on the data between 1990 and 2014 and tested it on the 2015 data, I will do the same here. Nonetheless, the exact number of examples I received here were not the same as what they reported which might be due to either update in the database since then or to differences in data cleaning (they do not provide code so I tried to reconstruct it based on their description)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "_uuid": "547ac62c41bb93702ea4df67921497034b3ce144"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(550, 13)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ind1 = gtd[(gtd.iyear >= 1990) \n",
    "    & (gtd.iyear <= 2015) \n",
    "    & (gtd.country_txt == 'India') \n",
    "    & (gtd.gname != 'Unknown')] \\\n",
    "    .loc[:, ['iyear', 'attacktype1', 'targtype1', 'targsubtype1', 'weaptype1', 'latitude',\n",
    "             'longitude', 'natlty1', 'property', 'INT_ANY', 'multiple', 'crit3', 'gname']]\n",
    "ind1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "_uuid": "d3b4a329803b4c87998344fe2f8958fe2f3f0ca9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(523, 13)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Here I do not impute missing values as they did and I also assume that they \n",
    "# dropped groups which are responsible only for single incident (within the examined period)\n",
    "ind1 = ind1.dropna(how='any')\n",
    "\n",
    "ind1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "_uuid": "3b3adc22ee776299004708b4fa0b292d25faea79"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(480, 13)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ind1 = ind1[ind1.gname.isin(ind1.gname.value_counts()[ind1.gname.value_counts() > 1].index.values)]\n",
    "ind1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind1_ = ind1.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "_uuid": "0eb568c78519e8511c279969e9026bf06962df9d"
   },
   "outputs": [],
   "source": [
    "X = ind1_[ind1_.iyear < 2015].drop(columns='gname')\n",
    "y = ind1_[ind1_.iyear < 2015].gname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "_uuid": "5b2167ce2c12122fdc9258d5545eec382271f48e"
   },
   "outputs": [],
   "source": [
    "validation_size = 0.2\n",
    "seed = 17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "_uuid": "0d386d8be1bc2918612657e9fb31a302e3da74cc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(352, 12)\n",
      "(89, 12)\n",
      "(352,)\n",
      "(89,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_validation, y_train, y_validation = train_test_split(X, y, test_size=validation_size, random_state=seed)\n",
    "print(X_train.shape)\n",
    "print(X_validation.shape)\n",
    "print(y_train.shape)\n",
    "print(y_validation.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "ee4c7bf9ab51ce2032e968f7f64e9eb1b43c2798"
   },
   "source": [
    "I try both SVM (the model they found to be the best) and Decision Tree Classifier (a model worked well in my analysis)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "_uuid": "cb4748f96239d727535e5bf6283b02296bec0981"
   },
   "outputs": [],
   "source": [
    "models = {\"Decisiong Tree Classifier\": DecisionTreeClassifier(),\n",
    "          'Support Vector Classifier': SVC(gamma='auto'),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "d8f70609292a201c2b6d18f39e88c56a9a14ca8a"
   },
   "source": [
    "They reported only accuracy scores so I will do the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "_uuid": "af6125fdc0de23fd0a2def218648c327bf8b3116"
   },
   "outputs": [],
   "source": [
    "def predict_groups(models, X_train, y_train):\n",
    "    for model in models:\n",
    "        #print(\"\\n{}:\\n\\n{}\\n\".format(model, models[model]))\n",
    "          \n",
    "        model_score = cross_val_score(models[model], X_train, y_train, cv=kfold, scoring='accuracy')\n",
    "        print(\"\\n{}:\\n\\tAccuracy: {} ({})\".format(model, model_score.mean(), model_score.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "_uuid": "4f15cac0b3a6ddd2094b6e689bdb84deaa2c5e95"
   },
   "outputs": [],
   "source": [
    "kfold = StratifiedKFold(n_splits=10, random_state=seed)\n",
    "#kfold = KFold(n_splits=10, random_state=seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "87628129c0597c9fa942c3cd0ce49d5a6d05c461"
   },
   "source": [
    "In the cross validation and without data imputations and feature extractio the Decision Tree Classifier produced a similar accuracy as they did (they reported 73.2%), but not with SVC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "_uuid": "148ea083fdae6bb74c315dfb625fcee63190b356"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/andras/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:605: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of members in any class cannot be less than n_splits=10.\n",
      "  % (min_groups, self.n_splits)), Warning)\n",
      "/home/andras/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:605: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of members in any class cannot be less than n_splits=10.\n",
      "  % (min_groups, self.n_splits)), Warning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Decisiong Tree Classifier:\n",
      "\tAccuracy: 0.7622079318530932 (0.11764011751208127)\n",
      "\n",
      "Support Vector Classifier:\n",
      "\tAccuracy: 0.5152506633151794 (0.1114993751737338)\n"
     ]
    }
   ],
   "source": [
    "predict_groups(models, X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also testing the 2015 year data (which was their own method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "_uuid": "1d3cdefe6101b40640ea2870a90f0dffb18426ce"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6410256410256411"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = DecisionTreeClassifier()\n",
    "model.fit(X, y)\n",
    "xtest = ind1[ind1.iyear == 2015].drop(columns='gname')\n",
    "ytest = ind1[ind1.iyear == 2015].gname\n",
    "(model.predict(xtest)  == ytest).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "_uuid": "461cb83932786f1ae2dc7fe84eef5711904fc3a7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3076923076923077"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = SVC()\n",
    "model.fit(X, y)\n",
    "(model.predict(ind1[ind1.iyear == 2015].drop(columns='gname').dropna(how='any'))  == ind1[ind1.iyear == 2015].gname).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are indeed much less than the reported results so I will try out their features with imputation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "a84ffd108fd274d6808b339ff33b321368526ce2"
   },
   "source": [
    "# <a id='f2'>[[2]](#2)</a> An Efficient Modelling of Terrorist Groups in India using Machine Learning Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "04018cedf8962b1b2da83298c3a0173026f15ae0"
   },
   "source": [
    "Varun Teja Gundabathula and V. Vaidhehi, An Efficient Modelling of Terrorist Groups in India using Machine Learning Algorithms, Indian Journal of Science and Technology, Vol 11(15), DOI: 10.17485/ijst/2018/v11i15/121766, April 2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "_uuid": "a871de9d802c76328dd519eb090c47fa3474f05e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(629, 14)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ind2 = gtd[(gtd.iyear >= 1970) \n",
    "    & (gtd.iyear <= 2015) \n",
    "    & (gtd.country_txt == 'India') \n",
    "    & (gtd.gname != 'Unknown')] \\\n",
    "    .loc[:, ['iyear', 'imonth', 'iday', 'extended', 'provstate', 'city', 'attacktype1_txt', 'targtype1_txt', \n",
    "             'nperps', 'weaptype1_txt', 'nkill', 'nwound', 'nhostkid', 'gname']]\n",
    "\n",
    "ind2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "a6a507613f8522f05fb3451154998fa82657ec65"
   },
   "source": [
    "Here, again, I receive a slightly different amount of the unique perpetrator groups from what the authors reported (270), probably due to update in the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "_uuid": "381d9a90172920fb65566c9ba268163ea96ae588"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "98"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ind2.gname.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "0fe84973909d7ed07ec699f96553c5aacffc4e68"
   },
   "source": [
    "The authors removed those groups which were linked to only one incident. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "_uuid": "d6560d672cf28c3da800400f3d44045d1c6d04c5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(579, 14)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ind2 = ind2[ind2.gname.isin(ind2.gname.value_counts()[ind2.gname.value_counts() > 1].index.values)]\n",
    "ind2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "_uuid": "c4469f3c6761eabb7bf38a0c4bd635873b0ce5d3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(579, 14)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ind2_ = ind2.copy()\n",
    "ind2_.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "They created a new column from the existing ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "_uuid": "51cea72b757013e2d19d71e6d46e4757f81ecc78",
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nkill</th>\n",
       "      <th>nwound</th>\n",
       "      <th>nhostkid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>571.000000</td>\n",
       "      <td>555.000000</td>\n",
       "      <td>75.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.073555</td>\n",
       "      <td>2.214414</td>\n",
       "      <td>3.76000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>4.744509</td>\n",
       "      <td>7.644810</td>\n",
       "      <td>5.29875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>62.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>36.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            nkill      nwound  nhostkid\n",
       "count  571.000000  555.000000  75.00000\n",
       "mean     2.073555    2.214414   3.76000\n",
       "std      4.744509    7.644810   5.29875\n",
       "min      0.000000    0.000000   1.00000\n",
       "25%      0.000000    0.000000   1.00000\n",
       "50%      1.000000    0.000000   2.00000\n",
       "75%      2.000000    1.000000   4.00000\n",
       "max     62.000000  100.000000  36.00000"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ind2_.loc[:, ['nkill', 'nwound', 'nhostkid']].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "They created a new column from the existing ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "_uuid": "80db91a3bb00d1d32a5fa408dfe1e379e0f4f8da"
   },
   "outputs": [],
   "source": [
    "crits = {'nkill': (62, 124, 'abc'), \n",
    "         'nwound': (272, 544, 'def'), \n",
    "         'nhostkid': (400, 800, 'ghi')}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "_uuid": "5e0d5a99981f5d94785b4f5ea2bd4370cb96b202"
   },
   "outputs": [],
   "source": [
    "def naff(data, crits):\n",
    "    n = pd.Series('_')\n",
    "    for key, i in zip(crits.keys(), range(len(crits))):\n",
    "        i = data.loc[:, key].copy()\n",
    "\n",
    "        i[data.loc[:,key] == 0] = 'n'\n",
    "        i[(data.loc[:,key] > 0) \n",
    "          & (data.loc[:,key] < crits[key][0])] = crits[key][2][2]\n",
    "        i[(data.loc[:,key] <= crits[key][1]) \n",
    "          & (data.loc[:,key] >= crits[key][0])] = crits[key][2][1]\n",
    "        i[data.loc[:,key] > crits[key][1]] = crits[key][2][0]\n",
    "\n",
    "        n = pd.concat((n, i), axis=1) \n",
    "\n",
    "    return n.drop(columns=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "_uuid": "3391b7e9285119be3092399b98250663fe5bd180",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nkill</th>\n",
       "      <th>nwound</th>\n",
       "      <th>nhostkid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9734</th>\n",
       "      <td>c</td>\n",
       "      <td>n</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16307</th>\n",
       "      <td>c</td>\n",
       "      <td>f</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19962</th>\n",
       "      <td>c</td>\n",
       "      <td>f</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20851</th>\n",
       "      <td>c</td>\n",
       "      <td>n</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20987</th>\n",
       "      <td>n</td>\n",
       "      <td>n</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21028</th>\n",
       "      <td>c</td>\n",
       "      <td>n</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21501</th>\n",
       "      <td>n</td>\n",
       "      <td>f</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21580</th>\n",
       "      <td>c</td>\n",
       "      <td>n</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21601</th>\n",
       "      <td>c</td>\n",
       "      <td>n</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      nkill nwound nhostkid\n",
       "0       NaN    NaN      NaN\n",
       "9734      c      n      NaN\n",
       "16307     c      f      NaN\n",
       "19962     c      f      NaN\n",
       "20851     c      n      NaN\n",
       "20987     n      n      NaN\n",
       "21028     c      n      NaN\n",
       "21501     n      f      NaN\n",
       "21580     c      n      NaN\n",
       "21601     c      n      NaN"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "naffect = naff(ind2_, crits)\n",
    "naffect.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "_uuid": "c41e5ac46bfa6af27034f1c8ea3d99950e4f2edf",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "i    75\n",
       "Name: nhostkid, dtype: int64"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "naffect.nhostkid.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dropping built-in missing codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "_uuid": "09a238ec0e29762ed2d31ba8f90deb5460aa5f1b"
   },
   "outputs": [],
   "source": [
    "naffect.nhostkid[naffect.nhostkid == -99] = np.NaN\n",
    "naffect.replace(np.NaN, 'n', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "_uuid": "e8d9a49299afd9cb2fd926f229dc578d61e1a887",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "naffect = naffect.iloc[:,0] +  naffect.iloc[:,1] +  naffect.iloc[:,2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The frequency of the new values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "_uuid": "299eba42daffe356fd46f93b0601564abe0ddcfc",
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nnn    183\n",
       "cnn    163\n",
       "cfn    106\n",
       "nfn     52\n",
       "cni     37\n",
       "nni     33\n",
       "cfi      3\n",
       "nfi      2\n",
       "bfn      1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "naffect.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We drop replace the old columns with the new one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "_uuid": "2bad1f54ed7b2948af1ae8566091ea57df8e6946"
   },
   "outputs": [],
   "source": [
    "ind2_.drop(columns=['nkill', 'nwound', 'nhostkid'], inplace=True)\n",
    "ind2_['naffect'] = naffect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "_uuid": "03921aaa47f51b11933e3d188e4dd356f7b16f61"
   },
   "outputs": [],
   "source": [
    "ind2_.nperps.where(ind2_.nperps != -99, 0, inplace=True)\n",
    "ind2_.nperps.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "_uuid": "ae67bdaa97a954b520b0c2d85a87112acb8744c5"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>iyear</th>\n",
       "      <th>imonth</th>\n",
       "      <th>iday</th>\n",
       "      <th>extended</th>\n",
       "      <th>provstate</th>\n",
       "      <th>city</th>\n",
       "      <th>attacktype1_txt</th>\n",
       "      <th>targtype1_txt</th>\n",
       "      <th>nperps</th>\n",
       "      <th>weaptype1_txt</th>\n",
       "      <th>gname</th>\n",
       "      <th>naffect</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>117537</th>\n",
       "      <td>2013</td>\n",
       "      <td>5</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>Uttar Pradesh</td>\n",
       "      <td>Kosi Kalan</td>\n",
       "      <td>Bombing/Explosion</td>\n",
       "      <td>Private Citizens &amp; Property</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Explosives/Bombs/Dynamite</td>\n",
       "      <td>Vishwa Hindu Parishad (VHP)</td>\n",
       "      <td>nfn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94010</th>\n",
       "      <td>2009</td>\n",
       "      <td>10</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>Jharkhand</td>\n",
       "      <td>Giridih district</td>\n",
       "      <td>Bombing/Explosion</td>\n",
       "      <td>Educational Institution</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Explosives/Bombs/Dynamite</td>\n",
       "      <td>Communist Party of India - Maoist (CPI-Maoist)</td>\n",
       "      <td>nnn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72495</th>\n",
       "      <td>2001</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>Maharashtra</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>Unarmed Assault</td>\n",
       "      <td>Religious Figures/Institutions</td>\n",
       "      <td>25.0</td>\n",
       "      <td>Melee</td>\n",
       "      <td>Vishwa Hindu Parishad (VHP)</td>\n",
       "      <td>nfn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58342</th>\n",
       "      <td>1995</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>Jammu and Kashmir</td>\n",
       "      <td>Jammu district</td>\n",
       "      <td>Bombing/Explosion</td>\n",
       "      <td>Utilities</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Explosives/Bombs/Dynamite</td>\n",
       "      <td>Kashmiri extremists</td>\n",
       "      <td>nnn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74240</th>\n",
       "      <td>2002</td>\n",
       "      <td>6</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>Jammu and Kashmir</td>\n",
       "      <td>Phraslan</td>\n",
       "      <td>Bombing/Explosion</td>\n",
       "      <td>Military</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Explosives/Bombs/Dynamite</td>\n",
       "      <td>Hizbul Mujahideen (HM)</td>\n",
       "      <td>cnn</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        iyear  imonth  iday  extended          provstate              city  \\\n",
       "117537   2013       5    30         0      Uttar Pradesh        Kosi Kalan   \n",
       "94010    2009      10    27         0          Jharkhand  Giridih district   \n",
       "72495    2001       8     6         0        Maharashtra            Mumbai   \n",
       "58342    1995       2     4         0  Jammu and Kashmir    Jammu district   \n",
       "74240    2002       6    27         0  Jammu and Kashmir          Phraslan   \n",
       "\n",
       "          attacktype1_txt                   targtype1_txt  nperps  \\\n",
       "117537  Bombing/Explosion     Private Citizens & Property     0.0   \n",
       "94010   Bombing/Explosion         Educational Institution     0.0   \n",
       "72495     Unarmed Assault  Religious Figures/Institutions    25.0   \n",
       "58342   Bombing/Explosion                       Utilities     0.0   \n",
       "74240   Bombing/Explosion                        Military     0.0   \n",
       "\n",
       "                    weaptype1_txt  \\\n",
       "117537  Explosives/Bombs/Dynamite   \n",
       "94010   Explosives/Bombs/Dynamite   \n",
       "72495                       Melee   \n",
       "58342   Explosives/Bombs/Dynamite   \n",
       "74240   Explosives/Bombs/Dynamite   \n",
       "\n",
       "                                                 gname naffect  \n",
       "117537                     Vishwa Hindu Parishad (VHP)     nfn  \n",
       "94010   Communist Party of India - Maoist (CPI-Maoist)     nnn  \n",
       "72495                      Vishwa Hindu Parishad (VHP)     nfn  \n",
       "58342                              Kashmiri extremists     nnn  \n",
       "74240                           Hizbul Mujahideen (HM)     cnn  "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ind2_.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rebalancing\n",
    "For their best results they used the SMOTE overbalancing algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "_uuid": "2ed54736722104c145a22fbf5a5f7dfb57de139b",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Communist Party of India - Maoist (CPI-Maoist)              168\n",
       "Sikh Extremists                                              78\n",
       "Maoists                                                      68\n",
       "United Liberation Front of Assam (ULFA)                      29\n",
       "Lashkar-e-Taiba (LeT)                                        20\n",
       "National Democratic Front of Bodoland (NDFB)                 18\n",
       "Muslim Separatists                                           16\n",
       "People's War Group (PWG)                                     14\n",
       "Hizbul Mujahideen (HM)                                       13\n",
       "Bodo Militants                                               12\n",
       "Garo National Liberation Army                                11\n",
       "Kashmiri extremists                                           9\n",
       "National Liberation Front of Tripura (NLFT)                   9\n",
       "Muslim Militants                                              9\n",
       "People's Liberation Army (India)                              7\n",
       "Jammu and Kashmir Liberation Front                            5\n",
       "Separatists                                                   5\n",
       "Dishmish Regiment                                             5\n",
       "People's Liberation Front of India                            5\n",
       "Khalistan Commando Force                                      4\n",
       "Kangleipak Communist Party (KCP)                              4\n",
       "Naxalites                                                     4\n",
       "Zeliangrong United Front                                      4\n",
       "United National Liberation Front (UNLF)                       4\n",
       "Maoist Communist Center (MCC)                                 4\n",
       "National Socialist Council of Nagaland-Khaplang (NSCN-K)      3\n",
       "Gurkha National Liberation Front (GNLF)                       3\n",
       "Jaish-e-Mohammad (JeM)                                        3\n",
       "Naga People                                                   3\n",
       "All Tripura Tiger Force (ATTF)                                3\n",
       "Tripura National Volunteers (TNV)                             3\n",
       "Militants                                                     3\n",
       "National Socialist Council of Nagaland                        3\n",
       "Vishwa Hindu Parishad (VHP)                                   2\n",
       "Coordination Committee (CORCOM)                               2\n",
       "Students Islamic Movement of India (SIMI)                     2\n",
       "Black Widows                                                  2\n",
       "United People's Democratic Solidarity (UPDS)                  2\n",
       "Tamil Nadu Liberation Army                                    2\n",
       "Achik National Volunteer Council-B (ANVC-B)                   2\n",
       "Tribal Group                                                  2\n",
       "Al-Mansoorian                                                 2\n",
       "Lashkar-e-Islam (India)                                       2\n",
       "People's Committee against Police Atrocities (PCPA)           2\n",
       "Al-Umar Mujahideen                                            2\n",
       "Al-Shuda Brigade                                              2\n",
       "Muslim extremists                                             2\n",
       "Gunmen                                                        2\n",
       "Name: gname, dtype: int64"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ind2_.gname.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "_uuid": "476b097eb084195ba0d12fb9bc13aa47b747793e",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(579, 484)\n",
      "(579,)\n"
     ]
    }
   ],
   "source": [
    "X = pd.get_dummies(ind2_.drop(columns='gname'), sparse=True)\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(ind2_.gname)\n",
    "\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "_uuid": "4424f564d6b5f2eef274c05b41f926101a277010",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 2,\n",
       " 1: 2,\n",
       " 2: 2,\n",
       " 3: 2,\n",
       " 4: 3,\n",
       " 5: 2,\n",
       " 6: 12,\n",
       " 7: 168,\n",
       " 8: 2,\n",
       " 9: 5,\n",
       " 10: 11,\n",
       " 11: 2,\n",
       " 12: 3,\n",
       " 13: 13,\n",
       " 14: 3,\n",
       " 15: 5,\n",
       " 16: 4,\n",
       " 17: 9,\n",
       " 18: 4,\n",
       " 19: 2,\n",
       " 20: 20,\n",
       " 21: 4,\n",
       " 22: 68,\n",
       " 23: 3,\n",
       " 24: 9,\n",
       " 25: 16,\n",
       " 26: 2,\n",
       " 27: 3,\n",
       " 28: 18,\n",
       " 29: 9,\n",
       " 30: 3,\n",
       " 31: 3,\n",
       " 32: 4,\n",
       " 33: 2,\n",
       " 34: 7,\n",
       " 35: 5,\n",
       " 36: 14,\n",
       " 37: 5,\n",
       " 38: 78,\n",
       " 39: 2,\n",
       " 40: 2,\n",
       " 41: 2,\n",
       " 42: 3,\n",
       " 43: 29,\n",
       " 44: 4,\n",
       " 45: 2,\n",
       " 46: 2,\n",
       " 47: 4}"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(np.array(np.unique(y, return_counts=True)).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "_uuid": "c8f7f9082329dde2cc40de88723ae420deaff2a9"
   },
   "outputs": [],
   "source": [
    "smote = SMOTE(ratio='all', k_neighbors=1, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "_uuid": "cf26ba85c04370651cbfb4235d1997b9b67924ce"
   },
   "outputs": [],
   "source": [
    "tXr, tyr = smote.fit_sample(X, y) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "_uuid": "6ab50acd24605d520b3d5415132932e7bcd64353",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(579, 484)\n",
      "(8064, 484)\n",
      "(579,)\n",
      "(8064,)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(tXr.shape)\n",
    "print(y.shape)\n",
    "print(tyr.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Label frequencies before and after rebalancing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "_uuid": "51ff4c191f96aa4a9feedb05c35d81ba28492362",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   2],\n",
       "       [  1,   2],\n",
       "       [  2,   2],\n",
       "       [  3,   2],\n",
       "       [  4,   3],\n",
       "       [  5,   2],\n",
       "       [  6,  12],\n",
       "       [  7, 168],\n",
       "       [  8,   2],\n",
       "       [  9,   5],\n",
       "       [ 10,  11],\n",
       "       [ 11,   2],\n",
       "       [ 12,   3],\n",
       "       [ 13,  13],\n",
       "       [ 14,   3],\n",
       "       [ 15,   5],\n",
       "       [ 16,   4],\n",
       "       [ 17,   9],\n",
       "       [ 18,   4],\n",
       "       [ 19,   2],\n",
       "       [ 20,  20],\n",
       "       [ 21,   4],\n",
       "       [ 22,  68],\n",
       "       [ 23,   3],\n",
       "       [ 24,   9],\n",
       "       [ 25,  16],\n",
       "       [ 26,   2],\n",
       "       [ 27,   3],\n",
       "       [ 28,  18],\n",
       "       [ 29,   9],\n",
       "       [ 30,   3],\n",
       "       [ 31,   3],\n",
       "       [ 32,   4],\n",
       "       [ 33,   2],\n",
       "       [ 34,   7],\n",
       "       [ 35,   5],\n",
       "       [ 36,  14],\n",
       "       [ 37,   5],\n",
       "       [ 38,  78],\n",
       "       [ 39,   2],\n",
       "       [ 40,   2],\n",
       "       [ 41,   2],\n",
       "       [ 42,   3],\n",
       "       [ 43,  29],\n",
       "       [ 44,   4],\n",
       "       [ 45,   2],\n",
       "       [ 46,   2],\n",
       "       [ 47,   4]])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([np.unique(y, return_counts=True)[0], np.unique(y, return_counts=True)[1]]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "_uuid": "2c2da6f9d00d36cf7c5b81ae187d6bf64495e0d9",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0, 168],\n",
       "       [  1, 168],\n",
       "       [  2, 168],\n",
       "       [  3, 168],\n",
       "       [  4, 168],\n",
       "       [  5, 168],\n",
       "       [  6, 168],\n",
       "       [  7, 168],\n",
       "       [  8, 168],\n",
       "       [  9, 168],\n",
       "       [ 10, 168],\n",
       "       [ 11, 168],\n",
       "       [ 12, 168],\n",
       "       [ 13, 168],\n",
       "       [ 14, 168],\n",
       "       [ 15, 168],\n",
       "       [ 16, 168],\n",
       "       [ 17, 168],\n",
       "       [ 18, 168],\n",
       "       [ 19, 168],\n",
       "       [ 20, 168],\n",
       "       [ 21, 168],\n",
       "       [ 22, 168],\n",
       "       [ 23, 168],\n",
       "       [ 24, 168],\n",
       "       [ 25, 168],\n",
       "       [ 26, 168],\n",
       "       [ 27, 168],\n",
       "       [ 28, 168],\n",
       "       [ 29, 168],\n",
       "       [ 30, 168],\n",
       "       [ 31, 168],\n",
       "       [ 32, 168],\n",
       "       [ 33, 168],\n",
       "       [ 34, 168],\n",
       "       [ 35, 168],\n",
       "       [ 36, 168],\n",
       "       [ 37, 168],\n",
       "       [ 38, 168],\n",
       "       [ 39, 168],\n",
       "       [ 40, 168],\n",
       "       [ 41, 168],\n",
       "       [ 42, 168],\n",
       "       [ 43, 168],\n",
       "       [ 44, 168],\n",
       "       [ 45, 168],\n",
       "       [ 46, 168],\n",
       "       [ 47, 168]])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([np.unique(tyr, return_counts=True)[0], np.unique(tyr, return_counts=True)[1]]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "_uuid": "c503023a4cbc311c811fad15181a0ac3312fbff9",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6451, 484)\n",
      "(1613, 484)\n",
      "(6451,)\n",
      "(1613,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_validation, y_train, y_validation = train_test_split(tXr, tyr, test_size=validation_size, random_state=seed)\n",
    "print(X_train.shape)\n",
    "print(X_validation.shape)\n",
    "print(y_train.shape)\n",
    "print(y_validation.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "_uuid": "180ef293b095fde617f6ce9b92c8f227f86f1855"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "73"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del tXr\n",
    "del tyr\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "_uuid": "781d1e52c5791a20f7bb26b32648b148f4240d14"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'multiclass'"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.utils.multiclass import type_of_target\n",
    "type_of_target(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "_uuid": "ad4102c91d1716c2ae293cd4aa21f7f0d42988ae"
   },
   "outputs": [],
   "source": [
    "models = {\"Decisiong Tree Classifier\": DecisionTreeClassifier(),\n",
    "          \"K-Neighbors Classifier\": KNeighborsClassifier(),\n",
    "          \"Gaussian Naive Bayes\": GaussianNB(),\n",
    "         }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "_uuid": "e37ca379fad0cb8cf46233624145356175cc310b"
   },
   "outputs": [],
   "source": [
    "def eval_models(models, X, y):\n",
    "    \"\"\"Evaluates selected model's prediction power on the cross-validated training datasets.\n",
    "    Takes\n",
    "        models: Dictionary of \"model_name\": model() pairs.\n",
    "        X: predictor attributes\n",
    "        y: target attribute\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    for model in models:\n",
    "        #print(\"Running {}...\".format(model))\n",
    "        #start = time.time()\n",
    "\n",
    "        result = []\n",
    "        result.append(model)\n",
    "\n",
    "        model_score = cross_validate(models[model],\n",
    "                                    X,\n",
    "                                    y,\n",
    "                                    scoring=['accuracy', # Evaluation metrics\n",
    "                                             'precision_micro',\n",
    "                                             'recall_micro',\n",
    "                                             'f1_micro',\n",
    "                                            # 'roc_auc'\n",
    "                                            ],\n",
    "                                    cv=kfold, # Cross-validation method\n",
    "                                    n_jobs=-1,\n",
    "                                    verbose=0,\n",
    "                                    return_train_score=False)\n",
    "\n",
    "        acc_mean = model_score['test_accuracy'].mean()\n",
    "        acc_std = model_score['test_accuracy'].std()\n",
    "        #auc_mean = model_score['test_roc_auc'].mean()\n",
    "        #auc_std = model_score['test_roc_auc'].std()\n",
    "\n",
    "        print(\"\\n{}:\\n\\tAccuracy: {} ({})\".format(model, acc_mean, acc_std)) #auc_std\n",
    "\n",
    "        #print(\"\\tROC AUC: {} ({})\".format(auc_mean, auc_std))\n",
    "\n",
    "        precision_micro_mean = model_score['test_precision_micro'].mean()\n",
    "        precision_micro_std = model_score['test_precision_micro'].std()\n",
    "        recall_micro_mean = model_score['test_recall_micro'].mean()\n",
    "        recall_micro_std = model_score['test_recall_micro'].std()\n",
    "\n",
    "        f1_micro_mean = model_score['test_f1_micro'].mean()\n",
    "        f1_micro_std = model_score['test_f1_micro'].std()\n",
    "        print(\"\\tF1 micro: {} ({})\".format(f1_micro_mean, f1_micro_std))\n",
    "\n",
    "        #result = result + [acc_mean, acc_std, auc_mean, auc_std]\n",
    "\n",
    "        dur = model_score['fit_time'].sum() + model_score['score_time'].sum()\n",
    "\n",
    "        print(\"\\tduration:{}\\n\".format(dur))\n",
    "        #result.append(dur)\n",
    "\n",
    "        #results.append(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cross validation produces extremely high accuracies which was also reported by the paper. This is might be the result of overfitting and, therefore, would need more examination."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "_uuid": "1bf18703d8415687025e65d1e6f57f9bcf38ab14"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Decisiong Tree Classifier:\n",
      "\tAccuracy: 0.9780300755926051 (0.0054627297147576215)\n",
      "\tF1 micro: 0.9780300755926051 (0.0054627297147576215)\n",
      "\tduration:13.52476191520691\n",
      "\n",
      "\n",
      "K-Neighbors Classifier:\n",
      "\tAccuracy: 0.9613700552864142 (0.0068195063114669914)\n",
      "\tF1 micro: 0.9613700552864142 (0.0068195063114669914)\n",
      "\tduration:23.754706144332886\n",
      "\n",
      "\n",
      "Gaussian Naive Bayes:\n",
      "\tAccuracy: 0.9725687495957647 (0.003094838019634866)\n",
      "\tF1 micro: 0.9725687495957647 (0.003094838019634866)\n",
      "\tduration:21.11389708518982\n",
      "\n"
     ]
    }
   ],
   "source": [
    "eval_models(models, X_train, y_train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
