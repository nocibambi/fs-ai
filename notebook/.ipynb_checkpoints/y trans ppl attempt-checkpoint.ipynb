{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "04018cedf8962b1b2da83298c3a0173026f15ae0"
   },
   "source": [
    "# Introduction\n",
    "\n",
    "In this notebook I try to replicate the main results of the following paper:\n",
    "> Varun Teja Gundabathula and V. Vaidhehi, An Efficient Modelling of Terrorist Groups in India using Machine Learning Algorithms, Indian Journal of Science and Technology, Vol 11(15), DOI: 10.17485/ijst/2018/v11i15/121766, April 2018\n",
    "\n",
    "There, the authors used to Global Terrorism Database to predict perpetrator groups based on different attributes of the past incidences."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "83836c143f355975927e87794ec4623269ecaca7"
   },
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "036573d721c9a4b43850b3944165a1a1ebc03a96"
   },
   "source": [
    "## Fundamentals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[H\u001b[2J"
     ]
    }
   ],
   "source": [
    "clear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_uuid": "c7f324db07bccfdbfd5c2f0022d31644e0ca7f4c",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "aa7b376e9a37065ae0b520e8955d5fec867d20d0"
   },
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_uuid": "e3db1d2dd0e97a9f9b86a3815af976a4fcaec092"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from scipy.sparse import csr_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "3b0c71acff1f801439272bd69d640a99601033c4"
   },
   "source": [
    "## Cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_uuid": "180fa7c8896feba5c6381cb2fd378cff5b96b023",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score, cross_validate, StratifiedKFold, StratifiedShuffleSplit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "9a73192d0be85a86a0ebd3ee0caf51dc854eb98d"
   },
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_uuid": "7f9e91269e4cc16d9a946d9770601127d8c2c138",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.svm import SVC\n",
    "#from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "95d3b74d5b7be112f3383dd7f32a252c85c59028"
   },
   "source": [
    "## Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_uuid": "3bbbc2e9a6fa8c5422a1acad20c2e1faaa21c843"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, classification_report, roc_auc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "3ba62c1eefd97e81969091a3b7a978285f09b7f9"
   },
   "source": [
    "## Memory management\n",
    "### Setting the temp folder\n",
    "This is required for \"jobs=-1\" to work on Kaggle at some cases (see https://www.kaggle.com/getting-started/45288#292143)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_uuid": "d85a1e3f02039ff73e726b555f34e42beac11d1c",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: JOBLIB_TEMP_FOLDER=/tmp\n"
     ]
    }
   ],
   "source": [
    "%env JOBLIB_TEMP_FOLDER=/tmp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "cf8fc810c8e9b57f51411b1e1fde9091844d94ed"
   },
   "source": [
    "## Garbage collector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_uuid": "832aefb4682ec12304963374e394be7f243775c3"
   },
   "outputs": [],
   "source": [
    "import gc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "86765176fbbaec74c331fac5e78d309086470267"
   },
   "source": [
    "# Loading the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "6715920cb093a258c58e2bed3586b984edbf13a4"
   },
   "source": [
    "Previously we loaded the data and created a sample out of it. From now on we are going to use it for our analysis and modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_uuid": "501699cf01c63eca9d29d0f84e878d94cee9d5cc"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/andras/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2785: DtypeWarning: Columns (4,6,31,33,53,61,62,63,76,79,90,92,94,96,114,115,121) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "# Instead of the excel from their homepage, I use the csv version they uploaded to Kaggle\n",
    "#gtd = pd.read_excel(\"globalterrorismdb_0617dist.xlsx\")\n",
    "gtd = pd.read_csv(\"./input/globalterrorismdb_0617dist.csv\", encoding='ISO-8859-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In case we want to use a sample\n",
    "gtd_ori = gtd\n",
    "gtd = gtd.sample(frac=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data transformations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "a84ffd108fd274d6808b339ff33b321368526ce2"
   },
   "source": [
    "The authors of the paper trained and tested the model on a subsample of the whole dataset, namely:\n",
    "* Between 1970-2015\n",
    "* Incidents related to India\n",
    "* Cases to which the dataset attributes a perpetrator group\n",
    "\n",
    "They also preselected a number of features for the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# II. Using a pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.base import TransformerMixin , BaseEstimator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "a84ffd108fd274d6808b339ff33b321368526ce2"
   },
   "source": [
    "The authors of the paper trained and tested the model on a subsample of the whole dataset, namely:\n",
    "* Between 1970-2015\n",
    "* Incidents related to India\n",
    "* Cases to which the dataset attributes a perpetrator group\n",
    "\n",
    "They also preselected a number of features for the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building the pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Description of steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Selecting samples\n",
    " - from India\n",
    " - between 1970 and 2015\n",
    " - those of which have known perpetartors\n",
    " - those of which belong to perpetrators with at least two connected incidents\n",
    "\n",
    "Affects the whole training dataset (both X and Y).\n",
    " \n",
    "2. Selecting columns\n",
    " - 'iyear'\n",
    " - 'imonth'\n",
    " - 'iday'\n",
    " - 'extended'\n",
    " - 'provstate'\n",
    " - 'city'\n",
    " - 'attacktype1_txt'\n",
    " - 'targtype1_txt'\n",
    " - 'nperps'\n",
    " - 'weaptype1_txt'\n",
    " - 'nkill'\n",
    " - 'nwound'\n",
    " - 'nhostkid'\n",
    "\n",
    "Affects only the training attributes.\n",
    "\n",
    "3. Creating a new attribute from the following three:\n",
    " - 'nkill'\n",
    " - 'nwound'\n",
    " - 'nhostkid'\n",
    "\n",
    "Affects only the training attributes.\n",
    "\n",
    "4. Converting the categorical attributes into binary form\n",
    "5. Converting the target labels into binary form\n",
    "\n",
    "\n",
    "\n",
    "6. Converting both the attributes and labels to sparse matrices\n",
    "7. Rebalancing the dataset based on the target classes\n",
    "8. Running the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_x</th>\n",
       "      <th>train_y</th>\n",
       "      <th>val_x</th>\n",
       "      <th>val_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Set location</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Problem dependent</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Set period</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Affects results</td>\n",
       "      <td>Affects results</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Only known samples</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Affects results</td>\n",
       "      <td>Affects results</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Only groups with more than 1 incident</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Affects results</td>\n",
       "      <td>Affects results</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Feature seleciton</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>New feature creation</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Binarizing X</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Binarize y</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Transfrom X to sparse</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Transform y to sparse</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SMOTE</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Affects model</td>\n",
       "      <td>Affects model</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      train_x train_y              val_x  \\\n",
       "Set location                                1       1  Problem dependent   \n",
       "Set period                                  1       1    Affects results   \n",
       "Only known samples                          1       1    Affects results   \n",
       "Only groups with more than 1 incident       1       1    Affects results   \n",
       "Feature seleciton                           1       0                  1   \n",
       "New feature creation                        1       0                  0   \n",
       "Binarizing X                                1       0                  1   \n",
       "Binarize y                                  0       1                  0   \n",
       "Transfrom X to sparse                       1       0                  1   \n",
       "Transform y to sparse                       1       0                  1   \n",
       "SMOTE                                       1       1      Affects model   \n",
       "\n",
       "                                                 val_y  \n",
       "Set location                                         1  \n",
       "Set period                             Affects results  \n",
       "Only known samples                     Affects results  \n",
       "Only groups with more than 1 incident  Affects results  \n",
       "Feature seleciton                                    0  \n",
       "New feature creation                                 0  \n",
       "Binarizing X                                         0  \n",
       "Binarize y                                           1  \n",
       "Transfrom X to sparse                                0  \n",
       "Transform y to sparse                                0  \n",
       "SMOTE                                    Affects model  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "steps_in_val_dict = {\n",
    "    'Set location': [1, 1, 'Problem dependent', 1],\n",
    "    'Set period': [1, 1, 'Affects results', 'Affects results'],\n",
    "    'Only known samples': [1, 1, 'Affects results', 'Affects results'],\n",
    "    'Only groups with more than 1 incident': [1, 1, 'Affects results', 'Affects results'],\n",
    "    'Feature seleciton': [1, 0, 1, 0],\n",
    "    'New feature creation': [1, 0, 0, 0],\n",
    "    'Binarizing X': [1, 0, 1, 0],\n",
    "    'Binarize y': [0, 1, 0, 1],\n",
    "    'Transfrom X to sparse': [1, 0, 1, 0],\n",
    "    'Transform y to sparse': [1, 0, 1, 0],\n",
    "    'SMOTE': [1, 1, 'Affects model', 'Affects model']\n",
    "}\n",
    "\n",
    "steps_in_val = pd.DataFrame(steps_in_val_dict, index=('train_x', 'train_y', 'val_x', 'val_y')).T\n",
    "steps_in_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "def showXy(X, y=None):\n",
    "        if isinstance(X, tuple):\n",
    "            print(\"X[0].shape: {}\".format(X[0].shape))\n",
    "            print(\"X[1].shape: {}\".format(X[1].shape))\n",
    "            \n",
    "        else:\n",
    "            print(\"X.shape: {}\".format(X.shape))\n",
    "            \n",
    "        if isinstance(y, (np.ndarray, pd.Series, tuple, pd.DataFrame, int)):\n",
    "            print(\"y.shape: {}\".format(y.shape))\n",
    "        \n",
    "        #print(\"self.y.shape: {}\".format(self.y.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CodeMergeNaff(TransformerMixin, BaseEstimator):\n",
    "    def __init__(self, col_bins_codes):\n",
    "        self.cbc = col_bins_codes\n",
    "        \n",
    "        #print(\"\\nCodeMergeNaff __init__\")\n",
    "        #showXy(X, y)\n",
    "        \n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        #print(\"\\nCodeMergeNaff fit START\")\n",
    "        #showXy(X, y)\n",
    "        \n",
    "        return self\n",
    "\n",
    "    def naff(self, X, crits):\n",
    "        #print(\"\\nCodeMergeNaff naff START\")\n",
    "        #showXy(X, y)        \n",
    "\n",
    "        n = pd.Series('_')\n",
    "        \n",
    "        for key, i in zip(crits.keys(), range(len(crits))):\n",
    "            i = X.loc[:, key].copy()\n",
    "\n",
    "            i[X.loc[:,key] == 0] = 'n'\n",
    "            i[(X.loc[:,key] > 0) \n",
    "              & (X.loc[:,key] < crits[key][0])] = crits[key][2][2]\n",
    "            i[(X.loc[:,key] <= crits[key][1]) \n",
    "              & (X.loc[:,key] >= crits[key][0])] = crits[key][2][1]\n",
    "            i[X.loc[:,key] > crits[key][1]] = crits[key][2][0]\n",
    "            \n",
    "            n = pd.concat((n, i), axis=1)\n",
    "            # print(n.columns)\n",
    "            \n",
    "        n.drop(columns=0, inplace=True)\n",
    "\n",
    "        #print(\"\\nCodeMergeNaff naff END\")\n",
    "        #showXy(X, y)\n",
    "\n",
    "        return n\n",
    "    \n",
    "    def transform(self, X):\n",
    "        print(\"\\nCodeMergeNaff transform START\")\n",
    "        #showXy(X, y)\n",
    "        \n",
    "        naffect = self.naff(X, self.cbc)\n",
    "        \n",
    "        naffect.nhostkid[naffect.nhostkid == -99] = np.NaN\n",
    "        naffect.replace(np.NaN, 'n', inplace=True)\n",
    "        naffect = naffect.iloc[:,0] +  naffect.iloc[:,1] +  naffect.iloc[:,2]\n",
    "        \n",
    "        X.drop(columns=['nkill', 'nwound', 'nhostkid'], inplace=True)\n",
    "        X['naffect'] = naffect\n",
    "\n",
    "        X.nperps.where(X.nperps != -99, 0, inplace=True)\n",
    "        X.nperps.fillna(0, inplace=True)\n",
    "        \n",
    "        print(\"CodeMergeNaff transform END\")\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProcPerf(TransformerMixin, BaseEstimator):\n",
    "    def __init__(self):\n",
    "        #print(\"\\nProcPerf __init__\")\n",
    "        #showXy(X, y)\n",
    "        pass\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        #print(\"\\nProcPerf fit START\")\n",
    "        #showXy(X, y)\n",
    "               \n",
    "        return self  \n",
    "\n",
    "    def dtypeconv(self, X):\n",
    "        #print(\"\\nProcPerf dtypeconv START\")\n",
    "        #showXy(X) # y\n",
    "        \n",
    "        X.loc[:,['imonth', 'iday', 'extended']] = X.loc[:,['imonth', 'iday', 'extended']]\\\n",
    "                                                   .astype('int8', copy=False) \n",
    "        \n",
    "        X.loc[:,['iyear', 'nperps']] = X.loc[:,['iyear', 'nperps']]\\\n",
    "                                        .astype('int16', copy=False)\n",
    "        \n",
    "        X.loc[:,X.select_dtypes(object).columns.values] = X.loc[:, X.select_dtypes(object).columns.values]\\\n",
    "                                                           .astype('category', copy=False)\n",
    "            \n",
    "        #print(\"\\nProcPerf dtypeconv END\")\n",
    "        #showXy(X) #y\n",
    "        #print(X.dtypes)\n",
    "\n",
    "        return X   \n",
    "\n",
    "    def cattobin(self, X, y):\n",
    "        #print(\"\\nProcPerf cattobin START\")\n",
    "        #showXy(X, y)\n",
    "               \n",
    "        X = pd.get_dummies(X)\n",
    "        X = csr_matrix(X)\n",
    "\n",
    "        label_encoder = LabelEncoder()\n",
    "        y = label_encoder.fit_transform(y)\n",
    "        y = y.astype('int16')\n",
    "        \n",
    "        #print(\"\\nProcPerf cattobin END\")\n",
    "        #showXy(X, y)\n",
    "        \n",
    "        return X, y\n",
    "    \n",
    "    def transform(self, X, y):\n",
    "        print(\"\\nProcPerf transform START\")\n",
    "        #showXy(X) #y\n",
    "        #print(\"self.y.shape: {}\".format(self.y.shape))\n",
    "        \n",
    "        y = y\n",
    "        \n",
    "        #X_naf = naff(X, crits)\n",
    "        X = self.dtypeconv(X)\n",
    "        X, y = self.cattobin(X, y)\n",
    "        \n",
    "        print(\"ProcPerf transform END\")\n",
    "        #showXy(X) #y\n",
    "        #print(\"self.y.shape: {}\".format(self.y.shape))\n",
    "                \n",
    "        return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GTDFilter(TransformerMixin, BaseEstimator):\n",
    "    '''\n",
    "    TransformerMixing; gives the `fit_transform` method (beyond `fit` and `transform`)\n",
    "    BaseEstimator: provides parameters usable for Grid search\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, startdate, enddate, country, columns, onlyknown=False,  min_inc=1):\n",
    "        self.sdate = startdate\n",
    "        self.edate = enddate\n",
    "        self.country = country\n",
    "        self.cols = columns\n",
    "        self.ok = onlyknown\n",
    "        self.minc = min_inc\n",
    "        \n",
    "        #print(\"\\nGTDFilter __init__\")\n",
    "        #showXy(X, y)\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        self.y = y\n",
    "    \n",
    "        print(\"\\nGTDFilter fit\")\n",
    "        showXy(X, y)\n",
    "        print(\"self.y.shape: {}\".format(self.y.shape))\n",
    "        \n",
    "        return self\n",
    "        \n",
    "    def transform(self, X, y):\n",
    "        print(\"\\nGTDFilter transform START\")\n",
    "        showXy(X, y)\n",
    "        print(\"self.y.shape: {}\".format(self.y.shape))\n",
    "        \n",
    "        #self.y_work = self.y\n",
    "        \n",
    "        if self.ok:\n",
    "            #nukcrit = self.y_work != 'Unknown'\n",
    "            nukcrit = y != 'Unknown'\n",
    "            X = X[nukcrit]\n",
    "            y = y[nukcrit]\n",
    "            # self.y_work = self.y_work[nukcrit]\n",
    "                           \n",
    "        filcrit = (X.iyear >= max(self.sdate, X.iyear.min())) \\\n",
    "                  & (X.iyear <= min(self.edate, X.iyear.max())) \\\n",
    "                  & (X.country_txt == 'India')\n",
    "        \n",
    "        X =  X[filcrit].loc[:,self.cols]\n",
    "        #self.y_work = self.y_work[filcrit]\n",
    "        y = y[filcrit]\n",
    "        \n",
    "        micrit = y.isin(y.value_counts() \\\n",
    "                        [y.value_counts() >= self.minc] \\\n",
    "                        .index.values)\n",
    "        \n",
    "        X = X[micrit]\n",
    "        y = y[micrit]\n",
    "        # self.y_work = self.y_work[micrit]\n",
    "        \n",
    "        print(\"GTDFilter transform END\")\n",
    "        showXy(X, y)\n",
    "        print(\"self.y.shape: {}\".format(self.y.shape))\n",
    "                \n",
    "        return X, y #self.y_work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransWrap(TransformerMixin, BaseEstimator):\n",
    "    def __init__(self, transformer, ytrans=False):\n",
    "        #print(\"\\nTransWrap __init__\")\n",
    "        #showXy(X, y)\n",
    "        \n",
    "        self.trans = transformer\n",
    "        self.ytrans = ytrans\n",
    "        self.actions = ('transform', 'sample', 'predict', 'score', 'params')\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        print(\"\\nTransWrap fit START\")\n",
    "        showXy(X, y)\n",
    "       \n",
    "        \n",
    "        self.y = y\n",
    "        print('self.y.shape: {}'.format(self.y.shape))\n",
    "    \n",
    "        if isinstance(X, tuple):\n",
    "            X, self.y = X[0], X[1]\n",
    "            #print(X.isna().any().any())\n",
    "            #print(X)\n",
    "            self.trans.fit(X, self.y)\n",
    "        else:\n",
    "            #print(X.isna().any().any())\n",
    "            self.trans.fit(X, y)\n",
    "        \n",
    "        return self\n",
    "\n",
    "    def predict(self, X, y=None):\n",
    "        y = self.y\n",
    "        \n",
    "        if isinstance(X, tuple):\n",
    "            X, self.y = X[0], X[1]\n",
    "        \n",
    "        return self.trans.predict(X)\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        y = self.y\n",
    "        return self.trans.predict_proba(X)\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        print(\"\\nTransWrap transform START\")\n",
    "        showXy(X) #y\n",
    "        print('self.y.shape: {}'.format(self.y.shape))\n",
    "        \n",
    "        y = self.y\n",
    "        \n",
    "        if isinstance(X, tuple):\n",
    "            X, y = X[0], X[1]\n",
    "            #self.y = y\n",
    "        \n",
    "        def select_action(actions, l):\n",
    "            if len(actions) > 0:\n",
    "                if actions[0] in dir(l):\n",
    "                    print(\"\\n{}\\n\\tAction: {}\".format(l, actions[0]))\n",
    "                    return actions[0]\n",
    "                return select_action(actions[1:], l)\n",
    "            else:\n",
    "                print(\"Transformer action is not within defined options.\")\n",
    "                return None\n",
    "        \n",
    "        action = select_action(self.actions, self.trans)\n",
    "               \n",
    "        if self.ytrans:\n",
    "            showXy(X, y)\n",
    "            # print(y)\n",
    "            new_X, new_y = getattr(self.trans, action)(X, y)\n",
    "            #if action == 'sample':\n",
    "            #    new_X, new_y = getattr(self.trans, action)(X, y)\n",
    "            #else:\n",
    "            #    new_X, new_y = getattr(self.trans, action)(X)\n",
    "\n",
    "        else:\n",
    "            new_X = getattr(self.trans, action)(X)\n",
    "            new_y = y\n",
    "            \n",
    "        print(\"TransWrap transform END\")\n",
    "        print(\"new_X.shape: {}\".format(new_X.shape))\n",
    "        print(\"new_y.shape: {}\".format(new_y.shape))\n",
    "\n",
    "        return new_X, new_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "_uuid": "80db91a3bb00d1d32a5fa408dfe1e379e0f4f8da"
   },
   "outputs": [],
   "source": [
    "crits = {'nkill': (62, 124, 'abc'), \n",
    "         'nwound': (272, 544, 'def'), \n",
    "         'nhostkid': (400, 800, 'ghi')}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pipe = Pipeline([\n",
    "    ('filter', TransWrap(GTDFilter(startdate=1970,\n",
    "                                           enddate=2015, \n",
    "                                           country='India', \n",
    "                                           onlyknown=True, \n",
    "                                           columns=('iyear', 'imonth', 'iday', 'extended', 'provstate', 'city',\n",
    "                                                    'attacktype1_txt', 'targtype1_txt',  'nperps', 'weaptype1_txt', \n",
    "                                                    'nkill', 'nwound', 'nhostkid'),\n",
    "                                           min_inc=2),\n",
    "                                 ytrans=True)),\n",
    "    ('naffect recoder', TransWrap(CodeMergeNaff(col_bins_codes=crits))),\n",
    "    ('perfproc', TransWrap(ProcPerf(), ytrans=True)),\n",
    "    #('smote', TransWrap(SMOTE(ratio='all', k_neighbors=1, n_jobs=-1), ytrans=True)),\n",
    "    #('DTC', TransWrap(DecisionTreeClassifier())),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "_uuid": "cd062f51c417ffa8e0238426622ebdde19fca480"
   },
   "outputs": [],
   "source": [
    "validation_size = 0.2\n",
    "seed = 17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "_uuid": "c503023a4cbc311c811fad15181a0ac3312fbff9",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13628, 134)\n",
      "(3407, 134)\n",
      "(13628,)\n",
      "(3407,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_validation, y_train, y_validation = train_test_split(gtd.drop(columns='gname'), gtd.gname, test_size=validation_size, random_state=seed)\n",
    "print(X_train.shape)\n",
    "print(X_validation.shape)\n",
    "print(y_train.shape)\n",
    "print(y_validation.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4 µs, sys: 0 ns, total: 4 µs\n",
      "Wall time: 11.4 µs\n",
      "\n",
      "TransWrap fit START\n",
      "X.shape: (13628, 134)\n",
      "y.shape: (13628,)\n",
      "self.y.shape: (13628,)\n",
      "\n",
      "GTDFilter fit\n",
      "X.shape: (13628, 134)\n",
      "y.shape: (13628,)\n",
      "self.y.shape: (13628,)\n",
      "\n",
      "TransWrap transform START\n",
      "X.shape: (13628, 134)\n",
      "self.y.shape: (13628,)\n",
      "\n",
      "GTDFilter(columns=None, country='India', enddate=None, min_inc=None,\n",
      "     onlyknown=None, startdate=None)\n",
      "\tAction: transform\n",
      "X.shape: (13628, 134)\n",
      "y.shape: (13628,)\n",
      "\n",
      "GTDFilter transform START\n",
      "X.shape: (13628, 134)\n",
      "y.shape: (13628,)\n",
      "self.y.shape: (13628,)\n",
      "GTDFilter transform END\n",
      "X.shape: (488, 13)\n",
      "y.shape: (488,)\n",
      "self.y.shape: (13628,)\n",
      "TransWrap transform END\n",
      "new_X.shape: (488, 13)\n",
      "new_y.shape: (488,)\n",
      "\n",
      "TransWrap fit START\n",
      "X[0].shape: (488, 13)\n",
      "X[1].shape: (488,)\n",
      "y.shape: (13628,)\n",
      "self.y.shape: (13628,)\n",
      "\n",
      "TransWrap transform START\n",
      "X[0].shape: (488, 13)\n",
      "X[1].shape: (488,)\n",
      "self.y.shape: (488,)\n",
      "\n",
      "CodeMergeNaff(col_bins_codes=None)\n",
      "\tAction: transform\n",
      "\n",
      "CodeMergeNaff transform START\n",
      "CodeMergeNaff transform END\n",
      "TransWrap transform END\n",
      "new_X.shape: (488, 11)\n",
      "new_y.shape: (488,)\n",
      "\n",
      "TransWrap fit START\n",
      "X[0].shape: (488, 11)\n",
      "X[1].shape: (488,)\n",
      "y.shape: (13628,)\n",
      "self.y.shape: (13628,)\n",
      "\n",
      "TransWrap transform START\n",
      "X[0].shape: (488, 11)\n",
      "X[1].shape: (488,)\n",
      "self.y.shape: (488,)\n",
      "\n",
      "ProcPerf()\n",
      "\tAction: transform\n",
      "X.shape: (488, 11)\n",
      "y.shape: (488,)\n",
      "\n",
      "ProcPerf transform START\n",
      "ProcPerf transform END\n",
      "TransWrap transform END\n",
      "new_X.shape: (488, 415)\n",
      "new_y.shape: (488,)\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "# result = pipe.predict(X_validation)\n",
    "transX, transy = pipe.fit_transform(X_train, y_train)\n",
    "#print(resX.describe())\n",
    "#print(resX.describe(include=object))\n",
    "#gtd.loc[resy.index,:].gname.value_counts()\n",
    "#gtd.loc[resX.index,:].country_txt.value_counts()\n",
    "#resy.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([5, 5, 4, ..., 1, 1, 1], dtype=int16),\n",
       " array([5, 5, 4, ..., 1, 1, 1], dtype=int16))"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6394,)"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resy.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8450,)"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resX[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(resX[1] == resX[0]).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected 2D array, got 1D array instead:\narray=[5. 5. 4. ... 1. 1. 1.].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-168-117ec0dea260>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDecisionTreeClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/tree/tree.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    788\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    789\u001b[0m             \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 790\u001b[0;31m             X_idx_sorted=X_idx_sorted)\n\u001b[0m\u001b[1;32m    791\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    792\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/tree/tree.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0mrandom_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_random_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m             \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDTYPE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"csc\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m             \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0missparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    439\u001b[0m                     \u001b[0;34m\"Reshape your data either using array.reshape(-1, 1) if \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m                     \u001b[0;34m\"your data has a single feature or array.reshape(1, -1) \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 441\u001b[0;31m                     \"if it contains a single sample.\".format(array))\n\u001b[0m\u001b[1;32m    442\u001b[0m             \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0matleast_2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    443\u001b[0m             \u001b[0;31m# To ensure that array flags are maintained\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Expected 2D array, got 1D array instead:\narray=[5. 5. 4. ... 1. 1. 1.].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample."
     ]
    }
   ],
   "source": [
    "model = DecisionTreeClassifier().fit(resX[0], resy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoring='accuracy'\n",
    "cv=3\n",
    "n_jobs=-1\n",
    "# max_features = 2500\n",
    "X = gtd.drop(columns='gname')\n",
    "y = gtd.gname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TransWrap fit START\n",
      "X.shape: (11356, 134)\n",
      "y.shape: (11356,)\n",
      "self.y.shape: (11356,)\n",
      "\n",
      "TransWrap fit START\n",
      "X.shape: (11357, 134)\n",
      "y.shape: (11357,)\n",
      "self.y.shape: (11357,)\n"
     ]
    },
    {
     "ename": "JoblibAttributeError",
     "evalue": "JoblibAttributeError\n___________________________________________________________________________\nMultiprocessing exception:\n...........................................................................\n/home/andras/anaconda3/lib/python3.6/runpy.py in _run_module_as_main(mod_name='ipykernel_launcher', alter_argv=1)\n    188         sys.exit(msg)\n    189     main_globals = sys.modules[\"__main__\"].__dict__\n    190     if alter_argv:\n    191         sys.argv[0] = mod_spec.origin\n    192     return _run_code(code, main_globals, None,\n--> 193                      \"__main__\", mod_spec)\n        mod_spec = ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.6/site-packages/ipykernel_launcher.py')\n    194 \n    195 def run_module(mod_name, init_globals=None,\n    196                run_name=None, alter_sys=False):\n    197     \"\"\"Execute a module's code without importing it\n\n...........................................................................\n/home/andras/anaconda3/lib/python3.6/runpy.py in _run_code(code=<code object <module> at 0x7f330fd368a0, file \"/...3.6/site-packages/ipykernel_launcher.py\", line 5>, run_globals={'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': '/home/andras/anaconda3/lib/python3.6/site-packages/__pycache__/ipykernel_launcher.cpython-36.pyc', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': '/home/andras/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': '', '__spec__': ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.6/site-packages/ipykernel_launcher.py'), 'app': <module 'ipykernel.kernelapp' from '/home/andras.../python3.6/site-packages/ipykernel/kernelapp.py'>, ...}, init_globals=None, mod_name='__main__', mod_spec=ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.6/site-packages/ipykernel_launcher.py'), pkg_name='', script_name=None)\n     80                        __cached__ = cached,\n     81                        __doc__ = None,\n     82                        __loader__ = loader,\n     83                        __package__ = pkg_name,\n     84                        __spec__ = mod_spec)\n---> 85     exec(code, run_globals)\n        code = <code object <module> at 0x7f330fd368a0, file \"/...3.6/site-packages/ipykernel_launcher.py\", line 5>\n        run_globals = {'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': '/home/andras/anaconda3/lib/python3.6/site-packages/__pycache__/ipykernel_launcher.cpython-36.pyc', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': '/home/andras/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': '', '__spec__': ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.6/site-packages/ipykernel_launcher.py'), 'app': <module 'ipykernel.kernelapp' from '/home/andras.../python3.6/site-packages/ipykernel/kernelapp.py'>, ...}\n     86     return run_globals\n     87 \n     88 def _run_module_code(code, init_globals=None,\n     89                     mod_name=None, mod_spec=None,\n\n...........................................................................\n/home/andras/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py in <module>()\n     11     # This is added back by InteractiveShellApp.init_path()\n     12     if sys.path[0] == '':\n     13         del sys.path[0]\n     14 \n     15     from ipykernel import kernelapp as app\n---> 16     app.launch_new_instance()\n\n...........................................................................\n/home/andras/anaconda3/lib/python3.6/site-packages/traitlets/config/application.py in launch_instance(cls=<class 'ipykernel.kernelapp.IPKernelApp'>, argv=None, **kwargs={})\n    653 \n    654         If a global instance already exists, this reinitializes and starts it\n    655         \"\"\"\n    656         app = cls.instance(**kwargs)\n    657         app.initialize(argv)\n--> 658         app.start()\n        app.start = <bound method IPKernelApp.start of <ipykernel.kernelapp.IPKernelApp object>>\n    659 \n    660 #-----------------------------------------------------------------------------\n    661 # utility functions, for convenience\n    662 #-----------------------------------------------------------------------------\n\n...........................................................................\n/home/andras/anaconda3/lib/python3.6/site-packages/ipykernel/kernelapp.py in start(self=<ipykernel.kernelapp.IPKernelApp object>)\n    481         if self.poller is not None:\n    482             self.poller.start()\n    483         self.kernel.start()\n    484         self.io_loop = ioloop.IOLoop.current()\n    485         try:\n--> 486             self.io_loop.start()\n        self.io_loop.start = <bound method BaseAsyncIOLoop.start of <tornado.platform.asyncio.AsyncIOMainLoop object>>\n    487         except KeyboardInterrupt:\n    488             pass\n    489 \n    490 launch_new_instance = IPKernelApp.launch_instance\n\n...........................................................................\n/home/andras/anaconda3/lib/python3.6/site-packages/tornado/platform/asyncio.py in start(self=<tornado.platform.asyncio.AsyncIOMainLoop object>)\n    122         except (RuntimeError, AssertionError):\n    123             old_loop = None\n    124         try:\n    125             self._setup_logging()\n    126             asyncio.set_event_loop(self.asyncio_loop)\n--> 127             self.asyncio_loop.run_forever()\n        self.asyncio_loop.run_forever = <bound method BaseEventLoop.run_forever of <_Uni...EventLoop running=True closed=False debug=False>>\n    128         finally:\n    129             asyncio.set_event_loop(old_loop)\n    130 \n    131     def stop(self):\n\n...........................................................................\n/home/andras/anaconda3/lib/python3.6/asyncio/base_events.py in run_forever(self=<_UnixSelectorEventLoop running=True closed=False debug=False>)\n    417             sys.set_asyncgen_hooks(firstiter=self._asyncgen_firstiter_hook,\n    418                                    finalizer=self._asyncgen_finalizer_hook)\n    419         try:\n    420             events._set_running_loop(self)\n    421             while True:\n--> 422                 self._run_once()\n        self._run_once = <bound method BaseEventLoop._run_once of <_UnixS...EventLoop running=True closed=False debug=False>>\n    423                 if self._stopping:\n    424                     break\n    425         finally:\n    426             self._stopping = False\n\n...........................................................................\n/home/andras/anaconda3/lib/python3.6/asyncio/base_events.py in _run_once(self=<_UnixSelectorEventLoop running=True closed=False debug=False>)\n   1429                         logger.warning('Executing %s took %.3f seconds',\n   1430                                        _format_handle(handle), dt)\n   1431                 finally:\n   1432                     self._current_handle = None\n   1433             else:\n-> 1434                 handle._run()\n        handle._run = <bound method Handle._run of <Handle BaseAsyncIOLoop._handle_events(11, 1)>>\n   1435         handle = None  # Needed to break cycles when an exception occurs.\n   1436 \n   1437     def _set_coroutine_wrapper(self, enabled):\n   1438         try:\n\n...........................................................................\n/home/andras/anaconda3/lib/python3.6/asyncio/events.py in _run(self=<Handle BaseAsyncIOLoop._handle_events(11, 1)>)\n    140             self._callback = None\n    141             self._args = None\n    142 \n    143     def _run(self):\n    144         try:\n--> 145             self._callback(*self._args)\n        self._callback = <bound method BaseAsyncIOLoop._handle_events of <tornado.platform.asyncio.AsyncIOMainLoop object>>\n        self._args = (11, 1)\n    146         except Exception as exc:\n    147             cb = _format_callback_source(self._callback, self._args)\n    148             msg = 'Exception in callback {}'.format(cb)\n    149             context = {\n\n...........................................................................\n/home/andras/anaconda3/lib/python3.6/site-packages/tornado/platform/asyncio.py in _handle_events(self=<tornado.platform.asyncio.AsyncIOMainLoop object>, fd=11, events=1)\n    112             self.writers.remove(fd)\n    113         del self.handlers[fd]\n    114 \n    115     def _handle_events(self, fd, events):\n    116         fileobj, handler_func = self.handlers[fd]\n--> 117         handler_func(fileobj, events)\n        handler_func = <function wrap.<locals>.null_wrapper>\n        fileobj = <zmq.sugar.socket.Socket object>\n        events = 1\n    118 \n    119     def start(self):\n    120         try:\n    121             old_loop = asyncio.get_event_loop()\n\n...........................................................................\n/home/andras/anaconda3/lib/python3.6/site-packages/tornado/stack_context.py in null_wrapper(*args=(<zmq.sugar.socket.Socket object>, 1), **kwargs={})\n    271         # Fast path when there are no active contexts.\n    272         def null_wrapper(*args, **kwargs):\n    273             try:\n    274                 current_state = _state.contexts\n    275                 _state.contexts = cap_contexts[0]\n--> 276                 return fn(*args, **kwargs)\n        args = (<zmq.sugar.socket.Socket object>, 1)\n        kwargs = {}\n    277             finally:\n    278                 _state.contexts = current_state\n    279         null_wrapper._wrapped = True\n    280         return null_wrapper\n\n...........................................................................\n/home/andras/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py in _handle_events(self=<zmq.eventloop.zmqstream.ZMQStream object>, fd=<zmq.sugar.socket.Socket object>, events=1)\n    445             return\n    446         zmq_events = self.socket.EVENTS\n    447         try:\n    448             # dispatch events:\n    449             if zmq_events & zmq.POLLIN and self.receiving():\n--> 450                 self._handle_recv()\n        self._handle_recv = <bound method ZMQStream._handle_recv of <zmq.eventloop.zmqstream.ZMQStream object>>\n    451                 if not self.socket:\n    452                     return\n    453             if zmq_events & zmq.POLLOUT and self.sending():\n    454                 self._handle_send()\n\n...........................................................................\n/home/andras/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py in _handle_recv(self=<zmq.eventloop.zmqstream.ZMQStream object>)\n    475             else:\n    476                 raise\n    477         else:\n    478             if self._recv_callback:\n    479                 callback = self._recv_callback\n--> 480                 self._run_callback(callback, msg)\n        self._run_callback = <bound method ZMQStream._run_callback of <zmq.eventloop.zmqstream.ZMQStream object>>\n        callback = <function wrap.<locals>.null_wrapper>\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    481         \n    482 \n    483     def _handle_send(self):\n    484         \"\"\"Handle a send event.\"\"\"\n\n...........................................................................\n/home/andras/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py in _run_callback(self=<zmq.eventloop.zmqstream.ZMQStream object>, callback=<function wrap.<locals>.null_wrapper>, *args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    427         close our socket.\"\"\"\n    428         try:\n    429             # Use a NullContext to ensure that all StackContexts are run\n    430             # inside our blanket exception handler rather than outside.\n    431             with stack_context.NullContext():\n--> 432                 callback(*args, **kwargs)\n        callback = <function wrap.<locals>.null_wrapper>\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    433         except:\n    434             gen_log.error(\"Uncaught exception in ZMQStream callback\",\n    435                           exc_info=True)\n    436             # Re-raise the exception so that IOLoop.handle_callback_exception\n\n...........................................................................\n/home/andras/anaconda3/lib/python3.6/site-packages/tornado/stack_context.py in null_wrapper(*args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    271         # Fast path when there are no active contexts.\n    272         def null_wrapper(*args, **kwargs):\n    273             try:\n    274                 current_state = _state.contexts\n    275                 _state.contexts = cap_contexts[0]\n--> 276                 return fn(*args, **kwargs)\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    277             finally:\n    278                 _state.contexts = current_state\n    279         null_wrapper._wrapped = True\n    280         return null_wrapper\n\n...........................................................................\n/home/andras/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py in dispatcher(msg=[<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>])\n    278         if self.control_stream:\n    279             self.control_stream.on_recv(self.dispatch_control, copy=False)\n    280 \n    281         def make_dispatcher(stream):\n    282             def dispatcher(msg):\n--> 283                 return self.dispatch_shell(stream, msg)\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    284             return dispatcher\n    285 \n    286         for s in self.shell_streams:\n    287             s.on_recv(make_dispatcher(s), copy=False)\n\n...........................................................................\n/home/andras/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py in dispatch_shell(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, msg={'buffers': [], 'content': {'allow_stdin': True, 'code': 'cross_val_score(estimator=pipe, X=X, y=y, scoring=scoring, cv=cv, n_jobs=n_jobs)', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2018, 8, 17, 11, 37, 31, 11184, tzinfo=tzutc()), 'msg_id': '73c896325b4dad10eee143b0bdb9f902', 'msg_type': 'execute_request', 'session': 'c783d31e4786cafb6480ce08b99df8a3', 'username': '', 'version': '5.2'}, 'metadata': {}, 'msg_id': '73c896325b4dad10eee143b0bdb9f902', 'msg_type': 'execute_request', 'parent_header': {}})\n    228             self.log.warn(\"Unknown message type: %r\", msg_type)\n    229         else:\n    230             self.log.debug(\"%s: %s\", msg_type, msg)\n    231             self.pre_handler_hook()\n    232             try:\n--> 233                 handler(stream, idents, msg)\n        handler = <bound method Kernel.execute_request of <ipykernel.ipkernel.IPythonKernel object>>\n        stream = <zmq.eventloop.zmqstream.ZMQStream object>\n        idents = [b'c783d31e4786cafb6480ce08b99df8a3']\n        msg = {'buffers': [], 'content': {'allow_stdin': True, 'code': 'cross_val_score(estimator=pipe, X=X, y=y, scoring=scoring, cv=cv, n_jobs=n_jobs)', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2018, 8, 17, 11, 37, 31, 11184, tzinfo=tzutc()), 'msg_id': '73c896325b4dad10eee143b0bdb9f902', 'msg_type': 'execute_request', 'session': 'c783d31e4786cafb6480ce08b99df8a3', 'username': '', 'version': '5.2'}, 'metadata': {}, 'msg_id': '73c896325b4dad10eee143b0bdb9f902', 'msg_type': 'execute_request', 'parent_header': {}}\n    234             except Exception:\n    235                 self.log.error(\"Exception in message handler:\", exc_info=True)\n    236             finally:\n    237                 self.post_handler_hook()\n\n...........................................................................\n/home/andras/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py in execute_request(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, ident=[b'c783d31e4786cafb6480ce08b99df8a3'], parent={'buffers': [], 'content': {'allow_stdin': True, 'code': 'cross_val_score(estimator=pipe, X=X, y=y, scoring=scoring, cv=cv, n_jobs=n_jobs)', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2018, 8, 17, 11, 37, 31, 11184, tzinfo=tzutc()), 'msg_id': '73c896325b4dad10eee143b0bdb9f902', 'msg_type': 'execute_request', 'session': 'c783d31e4786cafb6480ce08b99df8a3', 'username': '', 'version': '5.2'}, 'metadata': {}, 'msg_id': '73c896325b4dad10eee143b0bdb9f902', 'msg_type': 'execute_request', 'parent_header': {}})\n    394         if not silent:\n    395             self.execution_count += 1\n    396             self._publish_execute_input(code, parent, self.execution_count)\n    397 \n    398         reply_content = self.do_execute(code, silent, store_history,\n--> 399                                         user_expressions, allow_stdin)\n        user_expressions = {}\n        allow_stdin = True\n    400 \n    401         # Flush output before sending the reply.\n    402         sys.stdout.flush()\n    403         sys.stderr.flush()\n\n...........................................................................\n/home/andras/anaconda3/lib/python3.6/site-packages/ipykernel/ipkernel.py in do_execute(self=<ipykernel.ipkernel.IPythonKernel object>, code='cross_val_score(estimator=pipe, X=X, y=y, scoring=scoring, cv=cv, n_jobs=n_jobs)', silent=False, store_history=True, user_expressions={}, allow_stdin=True)\n    203 \n    204         self._forward_input(allow_stdin)\n    205 \n    206         reply_content = {}\n    207         try:\n--> 208             res = shell.run_cell(code, store_history=store_history, silent=silent)\n        res = undefined\n        shell.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = 'cross_val_score(estimator=pipe, X=X, y=y, scoring=scoring, cv=cv, n_jobs=n_jobs)'\n        store_history = True\n        silent = False\n    209         finally:\n    210             self._restore_input()\n    211 \n    212         if res.error_before_exec is not None:\n\n...........................................................................\n/home/andras/anaconda3/lib/python3.6/site-packages/ipykernel/zmqshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, *args=('cross_val_score(estimator=pipe, X=X, y=y, scoring=scoring, cv=cv, n_jobs=n_jobs)',), **kwargs={'silent': False, 'store_history': True})\n    532             )\n    533         self.payload_manager.write_payload(payload)\n    534 \n    535     def run_cell(self, *args, **kwargs):\n    536         self._last_traceback = None\n--> 537         return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n        self.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        args = ('cross_val_score(estimator=pipe, X=X, y=y, scoring=scoring, cv=cv, n_jobs=n_jobs)',)\n        kwargs = {'silent': False, 'store_history': True}\n    538 \n    539     def _showtraceback(self, etype, evalue, stb):\n    540         # try to preserve ordering of tracebacks and print statements\n    541         sys.stdout.flush()\n\n...........................................................................\n/home/andras/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, raw_cell='cross_val_score(estimator=pipe, X=X, y=y, scoring=scoring, cv=cv, n_jobs=n_jobs)', store_history=True, silent=False, shell_futures=True)\n   2657         -------\n   2658         result : :class:`ExecutionResult`\n   2659         \"\"\"\n   2660         try:\n   2661             result = self._run_cell(\n-> 2662                 raw_cell, store_history, silent, shell_futures)\n        raw_cell = 'cross_val_score(estimator=pipe, X=X, y=y, scoring=scoring, cv=cv, n_jobs=n_jobs)'\n        store_history = True\n        silent = False\n        shell_futures = True\n   2663         finally:\n   2664             self.events.trigger('post_execute')\n   2665             if not silent:\n   2666                 self.events.trigger('post_run_cell', result)\n\n...........................................................................\n/home/andras/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py in _run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, raw_cell='cross_val_score(estimator=pipe, X=X, y=y, scoring=scoring, cv=cv, n_jobs=n_jobs)', store_history=True, silent=False, shell_futures=True)\n   2780                 self.displayhook.exec_result = result\n   2781 \n   2782                 # Execute the user code\n   2783                 interactivity = 'none' if silent else self.ast_node_interactivity\n   2784                 has_raised = self.run_ast_nodes(code_ast.body, cell_name,\n-> 2785                    interactivity=interactivity, compiler=compiler, result=result)\n        interactivity = 'last_expr'\n        compiler = <IPython.core.compilerop.CachingCompiler object>\n   2786                 \n   2787                 self.last_execution_succeeded = not has_raised\n   2788                 self.last_execution_result = result\n   2789 \n\n...........................................................................\n/home/andras/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py in run_ast_nodes(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, nodelist=[<_ast.Expr object>], cell_name='<ipython-input-148-1acc040c3d6c>', interactivity='last', compiler=<IPython.core.compilerop.CachingCompiler object>, result=<ExecutionResult object at 7f32c78fe940, executi...rue silent=False shell_futures=True> result=None>)\n   2904                     return True\n   2905 \n   2906             for i, node in enumerate(to_run_interactive):\n   2907                 mod = ast.Interactive([node])\n   2908                 code = compiler(mod, cell_name, \"single\")\n-> 2909                 if self.run_code(code, result):\n        self.run_code = <bound method InteractiveShell.run_code of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = <code object <module> at 0x7f32c73dd270, file \"<ipython-input-148-1acc040c3d6c>\", line 1>\n        result = <ExecutionResult object at 7f32c78fe940, executi...rue silent=False shell_futures=True> result=None>\n   2910                     return True\n   2911 \n   2912             # Flush softspace\n   2913             if softspace(sys.stdout, 0):\n\n...........................................................................\n/home/andras/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py in run_code(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, code_obj=<code object <module> at 0x7f32c73dd270, file \"<ipython-input-148-1acc040c3d6c>\", line 1>, result=<ExecutionResult object at 7f32c78fe940, executi...rue silent=False shell_futures=True> result=None>)\n   2958         outflag = True  # happens in more places, so it's easier as default\n   2959         try:\n   2960             try:\n   2961                 self.hooks.pre_run_code_hook()\n   2962                 #rprint('Running code', repr(code_obj)) # dbg\n-> 2963                 exec(code_obj, self.user_global_ns, self.user_ns)\n        code_obj = <code object <module> at 0x7f32c73dd270, file \"<ipython-input-148-1acc040c3d6c>\", line 1>\n        self.user_global_ns = {'BaseEstimator': <class 'sklearn.base.BaseEstimator'>, 'CodeMergeNaff': <class '__main__.CodeMergeNaff'>, 'DecisionTreeClassifier': <class 'sklearn.tree.tree.DecisionTreeClassifier'>, 'GTDFilter': <class '__main__.GTDFilter'>, 'GaussianNB': <class 'sklearn.naive_bayes.GaussianNB'>, 'In': ['', \"get_ipython().run_line_magic('clear', '')\", 'import pandas as pd\\nimport numpy as np', 'from sklearn.preprocessing import LabelEncoder\\nf... import SMOTE\\nfrom scipy.sparse import csr_matrix', 'from sklearn.model_selection import train_test_s...validate, StratifiedKFold, StratifiedShuffleSplit', 'from sklearn.tree import DecisionTreeClassifier\\n...om sklearn.linear_model import LogisticRegression', 'from sklearn.metrics import accuracy_score, precision_score, classification_report, roc_auc_score', \"get_ipython().run_line_magic('env', 'JOBLIB_TEMP_FOLDER=/tmp')\", 'import gc', '# Instead of the excel from their homepage, I us...terrorismdb_0617dist.csv\", encoding=\\'ISO-8859-1\\')', '# In case we want to use a sample\\ngtd_ori = gtd\\ngtd = gtd.sample(frac=0.1)', \"dat = gtd[(gtd.iyear >= 1970) \\n    & (gtd.iyear ...', 'nwound', 'nhostkid', 'gname']]    \\n\\ndat.shape\", 'from sklearn.pipeline import Pipeline\\nfrom sklearn.base import TransformerMixin , BaseEstimator', \"steps_in_val_dict = {\\n    'Set location': [1, 1,..._x', 'train_y', 'val_x', 'val_y')).T\\nsteps_in_val\", 'def showXy(X, y=None):\\n        if isinstance(X, ...\\n            print(\"y.shape: {}\".format(y.shape))', 'class CodeMergeNaff(TransformerMixin, BaseEstima...t(\"CodeMergeNaff transform END\")\\n        return X', 'class ProcPerf(TransformerMixin, BaseEstimator):...lf.y.shape))\\n                \\n        return X, y', 'class GTDFilter(TransformerMixin, BaseEstimator)...                \\n        return X, y #self.y_work', 'class TransWrap(TransformerMixin, BaseEstimator)...format(new_y.shape))\\n\\n        return new_X, new_y', \"crits = {'nkill': (62, 124, 'abc'), \\n         'n... 'def'), \\n         'nhostkid': (400, 800, 'ghi')}\", ...], 'KFold': <class 'sklearn.model_selection._split.KFold'>, 'KNeighborsClassifier': <class 'sklearn.neighbors.classification.KNeighborsClassifier'>, 'LabelEncoder': <class 'sklearn.preprocessing.label.LabelEncoder'>, 'LinearDiscriminantAnalysis': <class 'sklearn.discriminant_analysis.LinearDiscriminantAnalysis'>, ...}\n        self.user_ns = {'BaseEstimator': <class 'sklearn.base.BaseEstimator'>, 'CodeMergeNaff': <class '__main__.CodeMergeNaff'>, 'DecisionTreeClassifier': <class 'sklearn.tree.tree.DecisionTreeClassifier'>, 'GTDFilter': <class '__main__.GTDFilter'>, 'GaussianNB': <class 'sklearn.naive_bayes.GaussianNB'>, 'In': ['', \"get_ipython().run_line_magic('clear', '')\", 'import pandas as pd\\nimport numpy as np', 'from sklearn.preprocessing import LabelEncoder\\nf... import SMOTE\\nfrom scipy.sparse import csr_matrix', 'from sklearn.model_selection import train_test_s...validate, StratifiedKFold, StratifiedShuffleSplit', 'from sklearn.tree import DecisionTreeClassifier\\n...om sklearn.linear_model import LogisticRegression', 'from sklearn.metrics import accuracy_score, precision_score, classification_report, roc_auc_score', \"get_ipython().run_line_magic('env', 'JOBLIB_TEMP_FOLDER=/tmp')\", 'import gc', '# Instead of the excel from their homepage, I us...terrorismdb_0617dist.csv\", encoding=\\'ISO-8859-1\\')', '# In case we want to use a sample\\ngtd_ori = gtd\\ngtd = gtd.sample(frac=0.1)', \"dat = gtd[(gtd.iyear >= 1970) \\n    & (gtd.iyear ...', 'nwound', 'nhostkid', 'gname']]    \\n\\ndat.shape\", 'from sklearn.pipeline import Pipeline\\nfrom sklearn.base import TransformerMixin , BaseEstimator', \"steps_in_val_dict = {\\n    'Set location': [1, 1,..._x', 'train_y', 'val_x', 'val_y')).T\\nsteps_in_val\", 'def showXy(X, y=None):\\n        if isinstance(X, ...\\n            print(\"y.shape: {}\".format(y.shape))', 'class CodeMergeNaff(TransformerMixin, BaseEstima...t(\"CodeMergeNaff transform END\")\\n        return X', 'class ProcPerf(TransformerMixin, BaseEstimator):...lf.y.shape))\\n                \\n        return X, y', 'class GTDFilter(TransformerMixin, BaseEstimator)...                \\n        return X, y #self.y_work', 'class TransWrap(TransformerMixin, BaseEstimator)...format(new_y.shape))\\n\\n        return new_X, new_y', \"crits = {'nkill': (62, 124, 'abc'), \\n         'n... 'def'), \\n         'nhostkid': (400, 800, 'ghi')}\", ...], 'KFold': <class 'sklearn.model_selection._split.KFold'>, 'KNeighborsClassifier': <class 'sklearn.neighbors.classification.KNeighborsClassifier'>, 'LabelEncoder': <class 'sklearn.preprocessing.label.LabelEncoder'>, 'LinearDiscriminantAnalysis': <class 'sklearn.discriminant_analysis.LinearDiscriminantAnalysis'>, ...}\n   2964             finally:\n   2965                 # Reset our crash handler in place\n   2966                 sys.excepthook = old_excepthook\n   2967         except SystemExit as e:\n\n...........................................................................\n/home/andras/Projects/fs-ai/notebook/<ipython-input-148-1acc040c3d6c> in <module>()\n----> 1 cross_val_score(estimator=pipe, X=X, y=y, scoring=scoring, cv=cv, n_jobs=n_jobs)\n\n...........................................................................\n/home/andras/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py in cross_val_score(estimator=Pipeline(memory=None,\n     steps=[('filter', Tra...TC', TransWrap(transformer=None, ytrans=False))]), X=             eventid  iyear  imonth  iday       ...                NaN  \n\n[17035 rows x 134 columns], y=18319                    Nicaraguan Democratic F...o Haram\nName: gname, Length: 17035, dtype: object, groups=None, scoring='accuracy', cv=3, n_jobs=-1, verbose=0, fit_params=None, pre_dispatch='2*n_jobs')\n    337     cv_results = cross_validate(estimator=estimator, X=X, y=y, groups=groups,\n    338                                 scoring={'score': scorer}, cv=cv,\n    339                                 return_train_score=False,\n    340                                 n_jobs=n_jobs, verbose=verbose,\n    341                                 fit_params=fit_params,\n--> 342                                 pre_dispatch=pre_dispatch)\n        pre_dispatch = '2*n_jobs'\n    343     return cv_results['test_score']\n    344 \n    345 \n    346 def _fit_and_score(estimator, X, y, scorer, train, test, verbose,\n\n...........................................................................\n/home/andras/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py in cross_validate(estimator=Pipeline(memory=None,\n     steps=[('filter', Tra...TC', TransWrap(transformer=None, ytrans=False))]), X=             eventid  iyear  imonth  iday       ...                NaN  \n\n[17035 rows x 134 columns], y=18319                    Nicaraguan Democratic F...o Haram\nName: gname, Length: 17035, dtype: object, groups=None, scoring={'score': make_scorer(accuracy_score)}, cv=KFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1, verbose=0, fit_params=None, pre_dispatch='2*n_jobs', return_train_score=False)\n    201     scores = parallel(\n    202         delayed(_fit_and_score)(\n    203             clone(estimator), X, y, scorers, train, test, verbose, None,\n    204             fit_params, return_train_score=return_train_score,\n    205             return_times=True)\n--> 206         for train, test in cv.split(X, y, groups))\n        cv.split = <bound method _BaseKFold.split of KFold(n_splits=3, random_state=None, shuffle=False)>\n        X =              eventid  iyear  imonth  iday       ...                NaN  \n\n[17035 rows x 134 columns]\n        y = 18319                    Nicaraguan Democratic F...o Haram\nName: gname, Length: 17035, dtype: object\n        groups = None\n    207 \n    208     if return_train_score:\n    209         train_scores, test_scores, fit_times, score_times = zip(*scores)\n    210         train_scores = _aggregate_score_dicts(train_scores)\n\n...........................................................................\n/home/andras/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=-1), iterable=<generator object cross_validate.<locals>.<genexpr>>)\n    784             if pre_dispatch == \"all\" or n_jobs == 1:\n    785                 # The iterable was consumed all at once by the above for loop.\n    786                 # No need to wait for async callbacks to trigger to\n    787                 # consumption.\n    788                 self._iterating = False\n--> 789             self.retrieve()\n        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=-1)>\n    790             # Make sure that we get a last message telling us we are done\n    791             elapsed_time = time.time() - self._start_time\n    792             self._print('Done %3i out of %3i | elapsed: %s finished',\n    793                         (len(self._output), len(self._output),\n\n---------------------------------------------------------------------------\nSub-process traceback:\n---------------------------------------------------------------------------\nAttributeError                                     Fri Aug 17 13:37:31 2018\nPID: 21903                  Python 3.6.6: /home/andras/anaconda3/bin/python\n...........................................................................\n/home/andras/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (Pipeline(memory=None,\n     steps=[('filter', Tra...TC', TransWrap(transformer=None, ytrans=False))]),              eventid  iyear  imonth  iday       ...                NaN  \n\n[17035 rows x 134 columns], 18319                    Nicaraguan Democratic F...o Haram\nName: gname, Length: 17035, dtype: object, {'score': make_scorer(accuracy_score)}, array([ 5679,  5680,  5681, ..., 17032, 17033, 17034]), array([   0,    1,    2, ..., 5676, 5677, 5678]), 0, None, None), {'return_times': True, 'return_train_score': False})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/home/andras/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (Pipeline(memory=None,\n     steps=[('filter', Tra...TC', TransWrap(transformer=None, ytrans=False))]),              eventid  iyear  imonth  iday       ...                NaN  \n\n[17035 rows x 134 columns], 18319                    Nicaraguan Democratic F...o Haram\nName: gname, Length: 17035, dtype: object, {'score': make_scorer(accuracy_score)}, array([ 5679,  5680,  5681, ..., 17032, 17033, 17034]), array([   0,    1,    2, ..., 5676, 5677, 5678]), 0, None, None)\n        kwargs = {'return_times': True, 'return_train_score': False}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/home/andras/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator=Pipeline(memory=None,\n     steps=[('filter', Tra...TC', TransWrap(transformer=None, ytrans=False))]), X=             eventid  iyear  imonth  iday       ...                NaN  \n\n[17035 rows x 134 columns], y=18319                    Nicaraguan Democratic F...o Haram\nName: gname, Length: 17035, dtype: object, scorer={'score': make_scorer(accuracy_score)}, train=array([ 5679,  5680,  5681, ..., 17032, 17033, 17034]), test=array([   0,    1,    2, ..., 5676, 5677, 5678]), verbose=0, parameters=None, fit_params={}, return_train_score=False, return_parameters=False, return_n_test_samples=False, return_times=True, error_score='raise')\n    453 \n    454     try:\n    455         if y_train is None:\n    456             estimator.fit(X_train, **fit_params)\n    457         else:\n--> 458             estimator.fit(X_train, y_train, **fit_params)\n        estimator.fit = <bound method Pipeline.fit of Pipeline(memory=No...C', TransWrap(transformer=None, ytrans=False))])>\n        X_train =              eventid  iyear  imonth  iday       ...                NaN  \n\n[11356 rows x 134 columns]\n        y_train = 61862                                           ...o Haram\nName: gname, Length: 11356, dtype: object\n        fit_params = {}\n    459 \n    460     except Exception as e:\n    461         # Note fit time as time until error\n    462         fit_time = time.time() - start_time\n\n...........................................................................\n/home/andras/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py in fit(self=Pipeline(memory=None,\n     steps=[('filter', Tra...TC', TransWrap(transformer=None, ytrans=False))]), X=             eventid  iyear  imonth  iday       ...                NaN  \n\n[11356 rows x 134 columns], y=61862                                           ...o Haram\nName: gname, Length: 11356, dtype: object, **fit_params={})\n    243         Returns\n    244         -------\n    245         self : Pipeline\n    246             This estimator\n    247         \"\"\"\n--> 248         Xt, fit_params = self._fit(X, y, **fit_params)\n        Xt = undefined\n        fit_params = {}\n        self._fit = <bound method Pipeline._fit of Pipeline(memory=N...C', TransWrap(transformer=None, ytrans=False))])>\n        X =              eventid  iyear  imonth  iday       ...                NaN  \n\n[11356 rows x 134 columns]\n        y = 61862                                           ...o Haram\nName: gname, Length: 11356, dtype: object\n    249         if self._final_estimator is not None:\n    250             self._final_estimator.fit(Xt, y, **fit_params)\n    251         return self\n    252 \n\n...........................................................................\n/home/andras/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py in _fit(self=Pipeline(memory=None,\n     steps=[('filter', Tra...TC', TransWrap(transformer=None, ytrans=False))]), X=             eventid  iyear  imonth  iday       ...                NaN  \n\n[11356 rows x 134 columns], y=61862                                           ...o Haram\nName: gname, Length: 11356, dtype: object, **fit_params={})\n    208                 else:\n    209                     cloned_transformer = clone(transformer)\n    210                 # Fit or load from cache the current transfomer\n    211                 Xt, fitted_transformer = fit_transform_one_cached(\n    212                     cloned_transformer, None, Xt, y,\n--> 213                     **fit_params_steps[name])\n        fit_params_steps = {'DTC': {}, 'filter': {}, 'naffect recoder': {}, 'perfproc': {}}\n        name = 'filter'\n    214                 # Replace the transformer of the step with the fitted\n    215                 # transformer. This is necessary when loading the transformer\n    216                 # from the cache.\n    217                 self.steps[step_idx] = (name, fitted_transformer)\n\n...........................................................................\n/home/andras/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/memory.py in __call__(self=NotMemorizedFunc(func=<function _fit_transform_one at 0x7f32ba29a7b8>), *args=(TransWrap(transformer=None, ytrans=True), None,              eventid  iyear  imonth  iday       ...                NaN  \n\n[11356 rows x 134 columns], 61862                                           ...o Haram\nName: gname, Length: 11356, dtype: object), **kwargs={})\n    357     # Should be a light as possible (for speed)\n    358     def __init__(self, func):\n    359         self.func = func\n    360 \n    361     def __call__(self, *args, **kwargs):\n--> 362         return self.func(*args, **kwargs)\n        self.func = <function _fit_transform_one>\n        args = (TransWrap(transformer=None, ytrans=True), None,              eventid  iyear  imonth  iday       ...                NaN  \n\n[11356 rows x 134 columns], 61862                                           ...o Haram\nName: gname, Length: 11356, dtype: object)\n        kwargs = {}\n    363 \n    364     def call_and_shelve(self, *args, **kwargs):\n    365         return NotMemorizedResult(self.func(*args, **kwargs))\n    366 \n\n...........................................................................\n/home/andras/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py in _fit_transform_one(transformer=TransWrap(transformer=None, ytrans=True), weight=None, X=             eventid  iyear  imonth  iday       ...                NaN  \n\n[11356 rows x 134 columns], y=61862                                           ...o Haram\nName: gname, Length: 11356, dtype: object, **fit_params={})\n    576 \n    577 \n    578 def _fit_transform_one(transformer, weight, X, y,\n    579                        **fit_params):\n    580     if hasattr(transformer, 'fit_transform'):\n--> 581         res = transformer.fit_transform(X, y, **fit_params)\n        res = undefined\n        transformer.fit_transform = <bound method TransformerMixin.fit_transform of TransWrap(transformer=None, ytrans=True)>\n        X =              eventid  iyear  imonth  iday       ...                NaN  \n\n[11356 rows x 134 columns]\n        y = 61862                                           ...o Haram\nName: gname, Length: 11356, dtype: object\n        fit_params = {}\n    582     else:\n    583         res = transformer.fit(X, y, **fit_params).transform(X)\n    584     # if we have a weight for this transformer, multiply output\n    585     if weight is None:\n\n...........................................................................\n/home/andras/anaconda3/lib/python3.6/site-packages/sklearn/base.py in fit_transform(self=TransWrap(transformer=None, ytrans=True), X=             eventid  iyear  imonth  iday       ...                NaN  \n\n[11356 rows x 134 columns], y=61862                                           ...o Haram\nName: gname, Length: 11356, dtype: object, **fit_params={})\n    515         if y is None:\n    516             # fit method of arity 1 (unsupervised transformation)\n    517             return self.fit(X, **fit_params).transform(X)\n    518         else:\n    519             # fit method of arity 2 (supervised transformation)\n--> 520             return self.fit(X, y, **fit_params).transform(X)\n        self.fit = <bound method TransWrap.fit of TransWrap(transformer=None, ytrans=True)>\n        X =              eventid  iyear  imonth  iday       ...                NaN  \n\n[11356 rows x 134 columns]\n        y = 61862                                           ...o Haram\nName: gname, Length: 11356, dtype: object\n        fit_params.transform = undefined\n    521 \n    522 \n    523 class DensityMixin(object):\n    524     \"\"\"Mixin class for all density estimators in scikit-learn.\"\"\"\n\n...........................................................................\n/home/andras/Projects/fs-ai/notebook/<ipython-input-140-a11be80f2199> in fit(self=TransWrap(transformer=None, ytrans=True), X=             eventid  iyear  imonth  iday       ...                NaN  \n\n[11356 rows x 134 columns], y=61862                                           ...o Haram\nName: gname, Length: 11356, dtype: object)\n     20             #print(X.isna().any().any())\n     21             #print(X)\n     22             self.trans.fit(X, self.y)\n     23         else:\n     24             #print(X.isna().any().any())\n---> 25             self.trans.fit(X, y)\n     26         \n     27         return self\n     28 \n     29     def predict(self, X, y=None):\n\nAttributeError: 'NoneType' object has no attribute 'fit'\n___________________________________________________________________________",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRemoteTraceback\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;31mRemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/home/andras/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\", line 350, in __call__\n    return self.func(*args, **kwargs)\n  File \"/home/andras/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\", line 131, in __call__\n    return [func(*args, **kwargs) for func, args, kwargs in self.items]\n  File \"/home/andras/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\", line 131, in <listcomp>\n    return [func(*args, **kwargs) for func, args, kwargs in self.items]\n  File \"/home/andras/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py\", line 458, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/home/andras/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py\", line 248, in fit\n    Xt, fit_params = self._fit(X, y, **fit_params)\n  File \"/home/andras/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py\", line 213, in _fit\n    **fit_params_steps[name])\n  File \"/home/andras/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/memory.py\", line 362, in __call__\n    return self.func(*args, **kwargs)\n  File \"/home/andras/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py\", line 581, in _fit_transform_one\n    res = transformer.fit_transform(X, y, **fit_params)\n  File \"/home/andras/anaconda3/lib/python3.6/site-packages/sklearn/base.py\", line 520, in fit_transform\n    return self.fit(X, y, **fit_params).transform(X)\n  File \"<ipython-input-140-a11be80f2199>\", line 25, in fit\n    self.trans.fit(X, y)\nAttributeError: 'NoneType' object has no attribute 'fit'\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/andras/anaconda3/lib/python3.6/multiprocessing/pool.py\", line 119, in worker\n    result = (True, func(*args, **kwds))\n  File \"/home/andras/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\", line 359, in __call__\n    raise TransportableException(text, e_type)\nsklearn.externals.joblib.my_exceptions.TransportableException: TransportableException\n___________________________________________________________________________\nAttributeError                                     Fri Aug 17 13:37:31 2018\nPID: 21903                  Python 3.6.6: /home/andras/anaconda3/bin/python\n...........................................................................\n/home/andras/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (Pipeline(memory=None,\n     steps=[('filter', Tra...TC', TransWrap(transformer=None, ytrans=False))]),              eventid  iyear  imonth  iday       ...                NaN  \n\n[17035 rows x 134 columns], 18319                    Nicaraguan Democratic F...o Haram\nName: gname, Length: 17035, dtype: object, {'score': make_scorer(accuracy_score)}, array([ 5679,  5680,  5681, ..., 17032, 17033, 17034]), array([   0,    1,    2, ..., 5676, 5677, 5678]), 0, None, None), {'return_times': True, 'return_train_score': False})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/home/andras/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (Pipeline(memory=None,\n     steps=[('filter', Tra...TC', TransWrap(transformer=None, ytrans=False))]),              eventid  iyear  imonth  iday       ...                NaN  \n\n[17035 rows x 134 columns], 18319                    Nicaraguan Democratic F...o Haram\nName: gname, Length: 17035, dtype: object, {'score': make_scorer(accuracy_score)}, array([ 5679,  5680,  5681, ..., 17032, 17033, 17034]), array([   0,    1,    2, ..., 5676, 5677, 5678]), 0, None, None)\n        kwargs = {'return_times': True, 'return_train_score': False}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/home/andras/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator=Pipeline(memory=None,\n     steps=[('filter', Tra...TC', TransWrap(transformer=None, ytrans=False))]), X=             eventid  iyear  imonth  iday       ...                NaN  \n\n[17035 rows x 134 columns], y=18319                    Nicaraguan Democratic F...o Haram\nName: gname, Length: 17035, dtype: object, scorer={'score': make_scorer(accuracy_score)}, train=array([ 5679,  5680,  5681, ..., 17032, 17033, 17034]), test=array([   0,    1,    2, ..., 5676, 5677, 5678]), verbose=0, parameters=None, fit_params={}, return_train_score=False, return_parameters=False, return_n_test_samples=False, return_times=True, error_score='raise')\n    453 \n    454     try:\n    455         if y_train is None:\n    456             estimator.fit(X_train, **fit_params)\n    457         else:\n--> 458             estimator.fit(X_train, y_train, **fit_params)\n        estimator.fit = <bound method Pipeline.fit of Pipeline(memory=No...C', TransWrap(transformer=None, ytrans=False))])>\n        X_train =              eventid  iyear  imonth  iday       ...                NaN  \n\n[11356 rows x 134 columns]\n        y_train = 61862                                           ...o Haram\nName: gname, Length: 11356, dtype: object\n        fit_params = {}\n    459 \n    460     except Exception as e:\n    461         # Note fit time as time until error\n    462         fit_time = time.time() - start_time\n\n...........................................................................\n/home/andras/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py in fit(self=Pipeline(memory=None,\n     steps=[('filter', Tra...TC', TransWrap(transformer=None, ytrans=False))]), X=             eventid  iyear  imonth  iday       ...                NaN  \n\n[11356 rows x 134 columns], y=61862                                           ...o Haram\nName: gname, Length: 11356, dtype: object, **fit_params={})\n    243         Returns\n    244         -------\n    245         self : Pipeline\n    246             This estimator\n    247         \"\"\"\n--> 248         Xt, fit_params = self._fit(X, y, **fit_params)\n        Xt = undefined\n        fit_params = {}\n        self._fit = <bound method Pipeline._fit of Pipeline(memory=N...C', TransWrap(transformer=None, ytrans=False))])>\n        X =              eventid  iyear  imonth  iday       ...                NaN  \n\n[11356 rows x 134 columns]\n        y = 61862                                           ...o Haram\nName: gname, Length: 11356, dtype: object\n    249         if self._final_estimator is not None:\n    250             self._final_estimator.fit(Xt, y, **fit_params)\n    251         return self\n    252 \n\n...........................................................................\n/home/andras/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py in _fit(self=Pipeline(memory=None,\n     steps=[('filter', Tra...TC', TransWrap(transformer=None, ytrans=False))]), X=             eventid  iyear  imonth  iday       ...                NaN  \n\n[11356 rows x 134 columns], y=61862                                           ...o Haram\nName: gname, Length: 11356, dtype: object, **fit_params={})\n    208                 else:\n    209                     cloned_transformer = clone(transformer)\n    210                 # Fit or load from cache the current transfomer\n    211                 Xt, fitted_transformer = fit_transform_one_cached(\n    212                     cloned_transformer, None, Xt, y,\n--> 213                     **fit_params_steps[name])\n        fit_params_steps = {'DTC': {}, 'filter': {}, 'naffect recoder': {}, 'perfproc': {}}\n        name = 'filter'\n    214                 # Replace the transformer of the step with the fitted\n    215                 # transformer. This is necessary when loading the transformer\n    216                 # from the cache.\n    217                 self.steps[step_idx] = (name, fitted_transformer)\n\n...........................................................................\n/home/andras/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/memory.py in __call__(self=NotMemorizedFunc(func=<function _fit_transform_one at 0x7f32ba29a7b8>), *args=(TransWrap(transformer=None, ytrans=True), None,              eventid  iyear  imonth  iday       ...                NaN  \n\n[11356 rows x 134 columns], 61862                                           ...o Haram\nName: gname, Length: 11356, dtype: object), **kwargs={})\n    357     # Should be a light as possible (for speed)\n    358     def __init__(self, func):\n    359         self.func = func\n    360 \n    361     def __call__(self, *args, **kwargs):\n--> 362         return self.func(*args, **kwargs)\n        self.func = <function _fit_transform_one>\n        args = (TransWrap(transformer=None, ytrans=True), None,              eventid  iyear  imonth  iday       ...                NaN  \n\n[11356 rows x 134 columns], 61862                                           ...o Haram\nName: gname, Length: 11356, dtype: object)\n        kwargs = {}\n    363 \n    364     def call_and_shelve(self, *args, **kwargs):\n    365         return NotMemorizedResult(self.func(*args, **kwargs))\n    366 \n\n...........................................................................\n/home/andras/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py in _fit_transform_one(transformer=TransWrap(transformer=None, ytrans=True), weight=None, X=             eventid  iyear  imonth  iday       ...                NaN  \n\n[11356 rows x 134 columns], y=61862                                           ...o Haram\nName: gname, Length: 11356, dtype: object, **fit_params={})\n    576 \n    577 \n    578 def _fit_transform_one(transformer, weight, X, y,\n    579                        **fit_params):\n    580     if hasattr(transformer, 'fit_transform'):\n--> 581         res = transformer.fit_transform(X, y, **fit_params)\n        res = undefined\n        transformer.fit_transform = <bound method TransformerMixin.fit_transform of TransWrap(transformer=None, ytrans=True)>\n        X =              eventid  iyear  imonth  iday       ...                NaN  \n\n[11356 rows x 134 columns]\n        y = 61862                                           ...o Haram\nName: gname, Length: 11356, dtype: object\n        fit_params = {}\n    582     else:\n    583         res = transformer.fit(X, y, **fit_params).transform(X)\n    584     # if we have a weight for this transformer, multiply output\n    585     if weight is None:\n\n...........................................................................\n/home/andras/anaconda3/lib/python3.6/site-packages/sklearn/base.py in fit_transform(self=TransWrap(transformer=None, ytrans=True), X=             eventid  iyear  imonth  iday       ...                NaN  \n\n[11356 rows x 134 columns], y=61862                                           ...o Haram\nName: gname, Length: 11356, dtype: object, **fit_params={})\n    515         if y is None:\n    516             # fit method of arity 1 (unsupervised transformation)\n    517             return self.fit(X, **fit_params).transform(X)\n    518         else:\n    519             # fit method of arity 2 (supervised transformation)\n--> 520             return self.fit(X, y, **fit_params).transform(X)\n        self.fit = <bound method TransWrap.fit of TransWrap(transformer=None, ytrans=True)>\n        X =              eventid  iyear  imonth  iday       ...                NaN  \n\n[11356 rows x 134 columns]\n        y = 61862                                           ...o Haram\nName: gname, Length: 11356, dtype: object\n        fit_params.transform = undefined\n    521 \n    522 \n    523 class DensityMixin(object):\n    524     \"\"\"Mixin class for all density estimators in scikit-learn.\"\"\"\n\n...........................................................................\n/home/andras/Projects/fs-ai/notebook/<ipython-input-140-a11be80f2199> in fit(self=TransWrap(transformer=None, ytrans=True), X=             eventid  iyear  imonth  iday       ...                NaN  \n\n[11356 rows x 134 columns], y=61862                                           ...o Haram\nName: gname, Length: 11356, dtype: object)\n     20             #print(X.isna().any().any())\n     21             #print(X)\n     22             self.trans.fit(X, self.y)\n     23         else:\n     24             #print(X.isna().any().any())\n---> 25             self.trans.fit(X, y)\n     26         \n     27         return self\n     28 \n     29     def predict(self, X, y=None):\n\nAttributeError: 'NoneType' object has no attribute 'fit'\n___________________________________________________________________________\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mTransportableException\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    698\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 699\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    700\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    643\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 644\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    645\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTransportableException\u001b[0m: TransportableException\n___________________________________________________________________________\nAttributeError                                     Fri Aug 17 13:37:31 2018\nPID: 21903                  Python 3.6.6: /home/andras/anaconda3/bin/python\n...........................................................................\n/home/andras/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (Pipeline(memory=None,\n     steps=[('filter', Tra...TC', TransWrap(transformer=None, ytrans=False))]),              eventid  iyear  imonth  iday       ...                NaN  \n\n[17035 rows x 134 columns], 18319                    Nicaraguan Democratic F...o Haram\nName: gname, Length: 17035, dtype: object, {'score': make_scorer(accuracy_score)}, array([ 5679,  5680,  5681, ..., 17032, 17033, 17034]), array([   0,    1,    2, ..., 5676, 5677, 5678]), 0, None, None), {'return_times': True, 'return_train_score': False})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/home/andras/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (Pipeline(memory=None,\n     steps=[('filter', Tra...TC', TransWrap(transformer=None, ytrans=False))]),              eventid  iyear  imonth  iday       ...                NaN  \n\n[17035 rows x 134 columns], 18319                    Nicaraguan Democratic F...o Haram\nName: gname, Length: 17035, dtype: object, {'score': make_scorer(accuracy_score)}, array([ 5679,  5680,  5681, ..., 17032, 17033, 17034]), array([   0,    1,    2, ..., 5676, 5677, 5678]), 0, None, None)\n        kwargs = {'return_times': True, 'return_train_score': False}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/home/andras/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator=Pipeline(memory=None,\n     steps=[('filter', Tra...TC', TransWrap(transformer=None, ytrans=False))]), X=             eventid  iyear  imonth  iday       ...                NaN  \n\n[17035 rows x 134 columns], y=18319                    Nicaraguan Democratic F...o Haram\nName: gname, Length: 17035, dtype: object, scorer={'score': make_scorer(accuracy_score)}, train=array([ 5679,  5680,  5681, ..., 17032, 17033, 17034]), test=array([   0,    1,    2, ..., 5676, 5677, 5678]), verbose=0, parameters=None, fit_params={}, return_train_score=False, return_parameters=False, return_n_test_samples=False, return_times=True, error_score='raise')\n    453 \n    454     try:\n    455         if y_train is None:\n    456             estimator.fit(X_train, **fit_params)\n    457         else:\n--> 458             estimator.fit(X_train, y_train, **fit_params)\n        estimator.fit = <bound method Pipeline.fit of Pipeline(memory=No...C', TransWrap(transformer=None, ytrans=False))])>\n        X_train =              eventid  iyear  imonth  iday       ...                NaN  \n\n[11356 rows x 134 columns]\n        y_train = 61862                                           ...o Haram\nName: gname, Length: 11356, dtype: object\n        fit_params = {}\n    459 \n    460     except Exception as e:\n    461         # Note fit time as time until error\n    462         fit_time = time.time() - start_time\n\n...........................................................................\n/home/andras/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py in fit(self=Pipeline(memory=None,\n     steps=[('filter', Tra...TC', TransWrap(transformer=None, ytrans=False))]), X=             eventid  iyear  imonth  iday       ...                NaN  \n\n[11356 rows x 134 columns], y=61862                                           ...o Haram\nName: gname, Length: 11356, dtype: object, **fit_params={})\n    243         Returns\n    244         -------\n    245         self : Pipeline\n    246             This estimator\n    247         \"\"\"\n--> 248         Xt, fit_params = self._fit(X, y, **fit_params)\n        Xt = undefined\n        fit_params = {}\n        self._fit = <bound method Pipeline._fit of Pipeline(memory=N...C', TransWrap(transformer=None, ytrans=False))])>\n        X =              eventid  iyear  imonth  iday       ...                NaN  \n\n[11356 rows x 134 columns]\n        y = 61862                                           ...o Haram\nName: gname, Length: 11356, dtype: object\n    249         if self._final_estimator is not None:\n    250             self._final_estimator.fit(Xt, y, **fit_params)\n    251         return self\n    252 \n\n...........................................................................\n/home/andras/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py in _fit(self=Pipeline(memory=None,\n     steps=[('filter', Tra...TC', TransWrap(transformer=None, ytrans=False))]), X=             eventid  iyear  imonth  iday       ...                NaN  \n\n[11356 rows x 134 columns], y=61862                                           ...o Haram\nName: gname, Length: 11356, dtype: object, **fit_params={})\n    208                 else:\n    209                     cloned_transformer = clone(transformer)\n    210                 # Fit or load from cache the current transfomer\n    211                 Xt, fitted_transformer = fit_transform_one_cached(\n    212                     cloned_transformer, None, Xt, y,\n--> 213                     **fit_params_steps[name])\n        fit_params_steps = {'DTC': {}, 'filter': {}, 'naffect recoder': {}, 'perfproc': {}}\n        name = 'filter'\n    214                 # Replace the transformer of the step with the fitted\n    215                 # transformer. This is necessary when loading the transformer\n    216                 # from the cache.\n    217                 self.steps[step_idx] = (name, fitted_transformer)\n\n...........................................................................\n/home/andras/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/memory.py in __call__(self=NotMemorizedFunc(func=<function _fit_transform_one at 0x7f32ba29a7b8>), *args=(TransWrap(transformer=None, ytrans=True), None,              eventid  iyear  imonth  iday       ...                NaN  \n\n[11356 rows x 134 columns], 61862                                           ...o Haram\nName: gname, Length: 11356, dtype: object), **kwargs={})\n    357     # Should be a light as possible (for speed)\n    358     def __init__(self, func):\n    359         self.func = func\n    360 \n    361     def __call__(self, *args, **kwargs):\n--> 362         return self.func(*args, **kwargs)\n        self.func = <function _fit_transform_one>\n        args = (TransWrap(transformer=None, ytrans=True), None,              eventid  iyear  imonth  iday       ...                NaN  \n\n[11356 rows x 134 columns], 61862                                           ...o Haram\nName: gname, Length: 11356, dtype: object)\n        kwargs = {}\n    363 \n    364     def call_and_shelve(self, *args, **kwargs):\n    365         return NotMemorizedResult(self.func(*args, **kwargs))\n    366 \n\n...........................................................................\n/home/andras/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py in _fit_transform_one(transformer=TransWrap(transformer=None, ytrans=True), weight=None, X=             eventid  iyear  imonth  iday       ...                NaN  \n\n[11356 rows x 134 columns], y=61862                                           ...o Haram\nName: gname, Length: 11356, dtype: object, **fit_params={})\n    576 \n    577 \n    578 def _fit_transform_one(transformer, weight, X, y,\n    579                        **fit_params):\n    580     if hasattr(transformer, 'fit_transform'):\n--> 581         res = transformer.fit_transform(X, y, **fit_params)\n        res = undefined\n        transformer.fit_transform = <bound method TransformerMixin.fit_transform of TransWrap(transformer=None, ytrans=True)>\n        X =              eventid  iyear  imonth  iday       ...                NaN  \n\n[11356 rows x 134 columns]\n        y = 61862                                           ...o Haram\nName: gname, Length: 11356, dtype: object\n        fit_params = {}\n    582     else:\n    583         res = transformer.fit(X, y, **fit_params).transform(X)\n    584     # if we have a weight for this transformer, multiply output\n    585     if weight is None:\n\n...........................................................................\n/home/andras/anaconda3/lib/python3.6/site-packages/sklearn/base.py in fit_transform(self=TransWrap(transformer=None, ytrans=True), X=             eventid  iyear  imonth  iday       ...                NaN  \n\n[11356 rows x 134 columns], y=61862                                           ...o Haram\nName: gname, Length: 11356, dtype: object, **fit_params={})\n    515         if y is None:\n    516             # fit method of arity 1 (unsupervised transformation)\n    517             return self.fit(X, **fit_params).transform(X)\n    518         else:\n    519             # fit method of arity 2 (supervised transformation)\n--> 520             return self.fit(X, y, **fit_params).transform(X)\n        self.fit = <bound method TransWrap.fit of TransWrap(transformer=None, ytrans=True)>\n        X =              eventid  iyear  imonth  iday       ...                NaN  \n\n[11356 rows x 134 columns]\n        y = 61862                                           ...o Haram\nName: gname, Length: 11356, dtype: object\n        fit_params.transform = undefined\n    521 \n    522 \n    523 class DensityMixin(object):\n    524     \"\"\"Mixin class for all density estimators in scikit-learn.\"\"\"\n\n...........................................................................\n/home/andras/Projects/fs-ai/notebook/<ipython-input-140-a11be80f2199> in fit(self=TransWrap(transformer=None, ytrans=True), X=             eventid  iyear  imonth  iday       ...                NaN  \n\n[11356 rows x 134 columns], y=61862                                           ...o Haram\nName: gname, Length: 11356, dtype: object)\n     20             #print(X.isna().any().any())\n     21             #print(X)\n     22             self.trans.fit(X, self.y)\n     23         else:\n     24             #print(X.isna().any().any())\n---> 25             self.trans.fit(X, y)\n     26         \n     27         return self\n     28 \n     29     def predict(self, X, y=None):\n\nAttributeError: 'NoneType' object has no attribute 'fit'\n___________________________________________________________________________",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mJoblibAttributeError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-148-1acc040c3d6c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcross_val_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpipe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscoring\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_val_score\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch)\u001b[0m\n\u001b[1;32m    340\u001b[0m                                 \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m                                 \u001b[0mfit_params\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 342\u001b[0;31m                                 pre_dispatch=pre_dispatch)\n\u001b[0m\u001b[1;32m    343\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mcv_results\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'test_score'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_validate\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score)\u001b[0m\n\u001b[1;32m    204\u001b[0m             \u001b[0mfit_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_train_score\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_train_score\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m             return_times=True)\n\u001b[0;32m--> 206\u001b[0;31m         for train, test in cv.split(X, y, groups))\n\u001b[0m\u001b[1;32m    207\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreturn_train_score\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    787\u001b[0m                 \u001b[0;31m# consumption.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 789\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    790\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    738\u001b[0m                     \u001b[0mexception\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexception_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreport\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    739\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 740\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mexception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    741\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    742\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mJoblibAttributeError\u001b[0m: JoblibAttributeError\n___________________________________________________________________________\nMultiprocessing exception:\n...........................................................................\n/home/andras/anaconda3/lib/python3.6/runpy.py in _run_module_as_main(mod_name='ipykernel_launcher', alter_argv=1)\n    188         sys.exit(msg)\n    189     main_globals = sys.modules[\"__main__\"].__dict__\n    190     if alter_argv:\n    191         sys.argv[0] = mod_spec.origin\n    192     return _run_code(code, main_globals, None,\n--> 193                      \"__main__\", mod_spec)\n        mod_spec = ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.6/site-packages/ipykernel_launcher.py')\n    194 \n    195 def run_module(mod_name, init_globals=None,\n    196                run_name=None, alter_sys=False):\n    197     \"\"\"Execute a module's code without importing it\n\n...........................................................................\n/home/andras/anaconda3/lib/python3.6/runpy.py in _run_code(code=<code object <module> at 0x7f330fd368a0, file \"/...3.6/site-packages/ipykernel_launcher.py\", line 5>, run_globals={'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': '/home/andras/anaconda3/lib/python3.6/site-packages/__pycache__/ipykernel_launcher.cpython-36.pyc', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': '/home/andras/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': '', '__spec__': ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.6/site-packages/ipykernel_launcher.py'), 'app': <module 'ipykernel.kernelapp' from '/home/andras.../python3.6/site-packages/ipykernel/kernelapp.py'>, ...}, init_globals=None, mod_name='__main__', mod_spec=ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.6/site-packages/ipykernel_launcher.py'), pkg_name='', script_name=None)\n     80                        __cached__ = cached,\n     81                        __doc__ = None,\n     82                        __loader__ = loader,\n     83                        __package__ = pkg_name,\n     84                        __spec__ = mod_spec)\n---> 85     exec(code, run_globals)\n        code = <code object <module> at 0x7f330fd368a0, file \"/...3.6/site-packages/ipykernel_launcher.py\", line 5>\n        run_globals = {'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': '/home/andras/anaconda3/lib/python3.6/site-packages/__pycache__/ipykernel_launcher.cpython-36.pyc', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': '/home/andras/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': '', '__spec__': ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.6/site-packages/ipykernel_launcher.py'), 'app': <module 'ipykernel.kernelapp' from '/home/andras.../python3.6/site-packages/ipykernel/kernelapp.py'>, ...}\n     86     return run_globals\n     87 \n     88 def _run_module_code(code, init_globals=None,\n     89                     mod_name=None, mod_spec=None,\n\n...........................................................................\n/home/andras/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py in <module>()\n     11     # This is added back by InteractiveShellApp.init_path()\n     12     if sys.path[0] == '':\n     13         del sys.path[0]\n     14 \n     15     from ipykernel import kernelapp as app\n---> 16     app.launch_new_instance()\n\n...........................................................................\n/home/andras/anaconda3/lib/python3.6/site-packages/traitlets/config/application.py in launch_instance(cls=<class 'ipykernel.kernelapp.IPKernelApp'>, argv=None, **kwargs={})\n    653 \n    654         If a global instance already exists, this reinitializes and starts it\n    655         \"\"\"\n    656         app = cls.instance(**kwargs)\n    657         app.initialize(argv)\n--> 658         app.start()\n        app.start = <bound method IPKernelApp.start of <ipykernel.kernelapp.IPKernelApp object>>\n    659 \n    660 #-----------------------------------------------------------------------------\n    661 # utility functions, for convenience\n    662 #-----------------------------------------------------------------------------\n\n...........................................................................\n/home/andras/anaconda3/lib/python3.6/site-packages/ipykernel/kernelapp.py in start(self=<ipykernel.kernelapp.IPKernelApp object>)\n    481         if self.poller is not None:\n    482             self.poller.start()\n    483         self.kernel.start()\n    484         self.io_loop = ioloop.IOLoop.current()\n    485         try:\n--> 486             self.io_loop.start()\n        self.io_loop.start = <bound method BaseAsyncIOLoop.start of <tornado.platform.asyncio.AsyncIOMainLoop object>>\n    487         except KeyboardInterrupt:\n    488             pass\n    489 \n    490 launch_new_instance = IPKernelApp.launch_instance\n\n...........................................................................\n/home/andras/anaconda3/lib/python3.6/site-packages/tornado/platform/asyncio.py in start(self=<tornado.platform.asyncio.AsyncIOMainLoop object>)\n    122         except (RuntimeError, AssertionError):\n    123             old_loop = None\n    124         try:\n    125             self._setup_logging()\n    126             asyncio.set_event_loop(self.asyncio_loop)\n--> 127             self.asyncio_loop.run_forever()\n        self.asyncio_loop.run_forever = <bound method BaseEventLoop.run_forever of <_Uni...EventLoop running=True closed=False debug=False>>\n    128         finally:\n    129             asyncio.set_event_loop(old_loop)\n    130 \n    131     def stop(self):\n\n...........................................................................\n/home/andras/anaconda3/lib/python3.6/asyncio/base_events.py in run_forever(self=<_UnixSelectorEventLoop running=True closed=False debug=False>)\n    417             sys.set_asyncgen_hooks(firstiter=self._asyncgen_firstiter_hook,\n    418                                    finalizer=self._asyncgen_finalizer_hook)\n    419         try:\n    420             events._set_running_loop(self)\n    421             while True:\n--> 422                 self._run_once()\n        self._run_once = <bound method BaseEventLoop._run_once of <_UnixS...EventLoop running=True closed=False debug=False>>\n    423                 if self._stopping:\n    424                     break\n    425         finally:\n    426             self._stopping = False\n\n...........................................................................\n/home/andras/anaconda3/lib/python3.6/asyncio/base_events.py in _run_once(self=<_UnixSelectorEventLoop running=True closed=False debug=False>)\n   1429                         logger.warning('Executing %s took %.3f seconds',\n   1430                                        _format_handle(handle), dt)\n   1431                 finally:\n   1432                     self._current_handle = None\n   1433             else:\n-> 1434                 handle._run()\n        handle._run = <bound method Handle._run of <Handle BaseAsyncIOLoop._handle_events(11, 1)>>\n   1435         handle = None  # Needed to break cycles when an exception occurs.\n   1436 \n   1437     def _set_coroutine_wrapper(self, enabled):\n   1438         try:\n\n...........................................................................\n/home/andras/anaconda3/lib/python3.6/asyncio/events.py in _run(self=<Handle BaseAsyncIOLoop._handle_events(11, 1)>)\n    140             self._callback = None\n    141             self._args = None\n    142 \n    143     def _run(self):\n    144         try:\n--> 145             self._callback(*self._args)\n        self._callback = <bound method BaseAsyncIOLoop._handle_events of <tornado.platform.asyncio.AsyncIOMainLoop object>>\n        self._args = (11, 1)\n    146         except Exception as exc:\n    147             cb = _format_callback_source(self._callback, self._args)\n    148             msg = 'Exception in callback {}'.format(cb)\n    149             context = {\n\n...........................................................................\n/home/andras/anaconda3/lib/python3.6/site-packages/tornado/platform/asyncio.py in _handle_events(self=<tornado.platform.asyncio.AsyncIOMainLoop object>, fd=11, events=1)\n    112             self.writers.remove(fd)\n    113         del self.handlers[fd]\n    114 \n    115     def _handle_events(self, fd, events):\n    116         fileobj, handler_func = self.handlers[fd]\n--> 117         handler_func(fileobj, events)\n        handler_func = <function wrap.<locals>.null_wrapper>\n        fileobj = <zmq.sugar.socket.Socket object>\n        events = 1\n    118 \n    119     def start(self):\n    120         try:\n    121             old_loop = asyncio.get_event_loop()\n\n...........................................................................\n/home/andras/anaconda3/lib/python3.6/site-packages/tornado/stack_context.py in null_wrapper(*args=(<zmq.sugar.socket.Socket object>, 1), **kwargs={})\n    271         # Fast path when there are no active contexts.\n    272         def null_wrapper(*args, **kwargs):\n    273             try:\n    274                 current_state = _state.contexts\n    275                 _state.contexts = cap_contexts[0]\n--> 276                 return fn(*args, **kwargs)\n        args = (<zmq.sugar.socket.Socket object>, 1)\n        kwargs = {}\n    277             finally:\n    278                 _state.contexts = current_state\n    279         null_wrapper._wrapped = True\n    280         return null_wrapper\n\n...........................................................................\n/home/andras/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py in _handle_events(self=<zmq.eventloop.zmqstream.ZMQStream object>, fd=<zmq.sugar.socket.Socket object>, events=1)\n    445             return\n    446         zmq_events = self.socket.EVENTS\n    447         try:\n    448             # dispatch events:\n    449             if zmq_events & zmq.POLLIN and self.receiving():\n--> 450                 self._handle_recv()\n        self._handle_recv = <bound method ZMQStream._handle_recv of <zmq.eventloop.zmqstream.ZMQStream object>>\n    451                 if not self.socket:\n    452                     return\n    453             if zmq_events & zmq.POLLOUT and self.sending():\n    454                 self._handle_send()\n\n...........................................................................\n/home/andras/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py in _handle_recv(self=<zmq.eventloop.zmqstream.ZMQStream object>)\n    475             else:\n    476                 raise\n    477         else:\n    478             if self._recv_callback:\n    479                 callback = self._recv_callback\n--> 480                 self._run_callback(callback, msg)\n        self._run_callback = <bound method ZMQStream._run_callback of <zmq.eventloop.zmqstream.ZMQStream object>>\n        callback = <function wrap.<locals>.null_wrapper>\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    481         \n    482 \n    483     def _handle_send(self):\n    484         \"\"\"Handle a send event.\"\"\"\n\n...........................................................................\n/home/andras/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py in _run_callback(self=<zmq.eventloop.zmqstream.ZMQStream object>, callback=<function wrap.<locals>.null_wrapper>, *args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    427         close our socket.\"\"\"\n    428         try:\n    429             # Use a NullContext to ensure that all StackContexts are run\n    430             # inside our blanket exception handler rather than outside.\n    431             with stack_context.NullContext():\n--> 432                 callback(*args, **kwargs)\n        callback = <function wrap.<locals>.null_wrapper>\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    433         except:\n    434             gen_log.error(\"Uncaught exception in ZMQStream callback\",\n    435                           exc_info=True)\n    436             # Re-raise the exception so that IOLoop.handle_callback_exception\n\n...........................................................................\n/home/andras/anaconda3/lib/python3.6/site-packages/tornado/stack_context.py in null_wrapper(*args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    271         # Fast path when there are no active contexts.\n    272         def null_wrapper(*args, **kwargs):\n    273             try:\n    274                 current_state = _state.contexts\n    275                 _state.contexts = cap_contexts[0]\n--> 276                 return fn(*args, **kwargs)\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    277             finally:\n    278                 _state.contexts = current_state\n    279         null_wrapper._wrapped = True\n    280         return null_wrapper\n\n...........................................................................\n/home/andras/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py in dispatcher(msg=[<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>])\n    278         if self.control_stream:\n    279             self.control_stream.on_recv(self.dispatch_control, copy=False)\n    280 \n    281         def make_dispatcher(stream):\n    282             def dispatcher(msg):\n--> 283                 return self.dispatch_shell(stream, msg)\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    284             return dispatcher\n    285 \n    286         for s in self.shell_streams:\n    287             s.on_recv(make_dispatcher(s), copy=False)\n\n...........................................................................\n/home/andras/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py in dispatch_shell(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, msg={'buffers': [], 'content': {'allow_stdin': True, 'code': 'cross_val_score(estimator=pipe, X=X, y=y, scoring=scoring, cv=cv, n_jobs=n_jobs)', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2018, 8, 17, 11, 37, 31, 11184, tzinfo=tzutc()), 'msg_id': '73c896325b4dad10eee143b0bdb9f902', 'msg_type': 'execute_request', 'session': 'c783d31e4786cafb6480ce08b99df8a3', 'username': '', 'version': '5.2'}, 'metadata': {}, 'msg_id': '73c896325b4dad10eee143b0bdb9f902', 'msg_type': 'execute_request', 'parent_header': {}})\n    228             self.log.warn(\"Unknown message type: %r\", msg_type)\n    229         else:\n    230             self.log.debug(\"%s: %s\", msg_type, msg)\n    231             self.pre_handler_hook()\n    232             try:\n--> 233                 handler(stream, idents, msg)\n        handler = <bound method Kernel.execute_request of <ipykernel.ipkernel.IPythonKernel object>>\n        stream = <zmq.eventloop.zmqstream.ZMQStream object>\n        idents = [b'c783d31e4786cafb6480ce08b99df8a3']\n        msg = {'buffers': [], 'content': {'allow_stdin': True, 'code': 'cross_val_score(estimator=pipe, X=X, y=y, scoring=scoring, cv=cv, n_jobs=n_jobs)', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2018, 8, 17, 11, 37, 31, 11184, tzinfo=tzutc()), 'msg_id': '73c896325b4dad10eee143b0bdb9f902', 'msg_type': 'execute_request', 'session': 'c783d31e4786cafb6480ce08b99df8a3', 'username': '', 'version': '5.2'}, 'metadata': {}, 'msg_id': '73c896325b4dad10eee143b0bdb9f902', 'msg_type': 'execute_request', 'parent_header': {}}\n    234             except Exception:\n    235                 self.log.error(\"Exception in message handler:\", exc_info=True)\n    236             finally:\n    237                 self.post_handler_hook()\n\n...........................................................................\n/home/andras/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py in execute_request(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, ident=[b'c783d31e4786cafb6480ce08b99df8a3'], parent={'buffers': [], 'content': {'allow_stdin': True, 'code': 'cross_val_score(estimator=pipe, X=X, y=y, scoring=scoring, cv=cv, n_jobs=n_jobs)', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2018, 8, 17, 11, 37, 31, 11184, tzinfo=tzutc()), 'msg_id': '73c896325b4dad10eee143b0bdb9f902', 'msg_type': 'execute_request', 'session': 'c783d31e4786cafb6480ce08b99df8a3', 'username': '', 'version': '5.2'}, 'metadata': {}, 'msg_id': '73c896325b4dad10eee143b0bdb9f902', 'msg_type': 'execute_request', 'parent_header': {}})\n    394         if not silent:\n    395             self.execution_count += 1\n    396             self._publish_execute_input(code, parent, self.execution_count)\n    397 \n    398         reply_content = self.do_execute(code, silent, store_history,\n--> 399                                         user_expressions, allow_stdin)\n        user_expressions = {}\n        allow_stdin = True\n    400 \n    401         # Flush output before sending the reply.\n    402         sys.stdout.flush()\n    403         sys.stderr.flush()\n\n...........................................................................\n/home/andras/anaconda3/lib/python3.6/site-packages/ipykernel/ipkernel.py in do_execute(self=<ipykernel.ipkernel.IPythonKernel object>, code='cross_val_score(estimator=pipe, X=X, y=y, scoring=scoring, cv=cv, n_jobs=n_jobs)', silent=False, store_history=True, user_expressions={}, allow_stdin=True)\n    203 \n    204         self._forward_input(allow_stdin)\n    205 \n    206         reply_content = {}\n    207         try:\n--> 208             res = shell.run_cell(code, store_history=store_history, silent=silent)\n        res = undefined\n        shell.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = 'cross_val_score(estimator=pipe, X=X, y=y, scoring=scoring, cv=cv, n_jobs=n_jobs)'\n        store_history = True\n        silent = False\n    209         finally:\n    210             self._restore_input()\n    211 \n    212         if res.error_before_exec is not None:\n\n...........................................................................\n/home/andras/anaconda3/lib/python3.6/site-packages/ipykernel/zmqshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, *args=('cross_val_score(estimator=pipe, X=X, y=y, scoring=scoring, cv=cv, n_jobs=n_jobs)',), **kwargs={'silent': False, 'store_history': True})\n    532             )\n    533         self.payload_manager.write_payload(payload)\n    534 \n    535     def run_cell(self, *args, **kwargs):\n    536         self._last_traceback = None\n--> 537         return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n        self.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        args = ('cross_val_score(estimator=pipe, X=X, y=y, scoring=scoring, cv=cv, n_jobs=n_jobs)',)\n        kwargs = {'silent': False, 'store_history': True}\n    538 \n    539     def _showtraceback(self, etype, evalue, stb):\n    540         # try to preserve ordering of tracebacks and print statements\n    541         sys.stdout.flush()\n\n...........................................................................\n/home/andras/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, raw_cell='cross_val_score(estimator=pipe, X=X, y=y, scoring=scoring, cv=cv, n_jobs=n_jobs)', store_history=True, silent=False, shell_futures=True)\n   2657         -------\n   2658         result : :class:`ExecutionResult`\n   2659         \"\"\"\n   2660         try:\n   2661             result = self._run_cell(\n-> 2662                 raw_cell, store_history, silent, shell_futures)\n        raw_cell = 'cross_val_score(estimator=pipe, X=X, y=y, scoring=scoring, cv=cv, n_jobs=n_jobs)'\n        store_history = True\n        silent = False\n        shell_futures = True\n   2663         finally:\n   2664             self.events.trigger('post_execute')\n   2665             if not silent:\n   2666                 self.events.trigger('post_run_cell', result)\n\n...........................................................................\n/home/andras/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py in _run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, raw_cell='cross_val_score(estimator=pipe, X=X, y=y, scoring=scoring, cv=cv, n_jobs=n_jobs)', store_history=True, silent=False, shell_futures=True)\n   2780                 self.displayhook.exec_result = result\n   2781 \n   2782                 # Execute the user code\n   2783                 interactivity = 'none' if silent else self.ast_node_interactivity\n   2784                 has_raised = self.run_ast_nodes(code_ast.body, cell_name,\n-> 2785                    interactivity=interactivity, compiler=compiler, result=result)\n        interactivity = 'last_expr'\n        compiler = <IPython.core.compilerop.CachingCompiler object>\n   2786                 \n   2787                 self.last_execution_succeeded = not has_raised\n   2788                 self.last_execution_result = result\n   2789 \n\n...........................................................................\n/home/andras/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py in run_ast_nodes(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, nodelist=[<_ast.Expr object>], cell_name='<ipython-input-148-1acc040c3d6c>', interactivity='last', compiler=<IPython.core.compilerop.CachingCompiler object>, result=<ExecutionResult object at 7f32c78fe940, executi...rue silent=False shell_futures=True> result=None>)\n   2904                     return True\n   2905 \n   2906             for i, node in enumerate(to_run_interactive):\n   2907                 mod = ast.Interactive([node])\n   2908                 code = compiler(mod, cell_name, \"single\")\n-> 2909                 if self.run_code(code, result):\n        self.run_code = <bound method InteractiveShell.run_code of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = <code object <module> at 0x7f32c73dd270, file \"<ipython-input-148-1acc040c3d6c>\", line 1>\n        result = <ExecutionResult object at 7f32c78fe940, executi...rue silent=False shell_futures=True> result=None>\n   2910                     return True\n   2911 \n   2912             # Flush softspace\n   2913             if softspace(sys.stdout, 0):\n\n...........................................................................\n/home/andras/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py in run_code(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, code_obj=<code object <module> at 0x7f32c73dd270, file \"<ipython-input-148-1acc040c3d6c>\", line 1>, result=<ExecutionResult object at 7f32c78fe940, executi...rue silent=False shell_futures=True> result=None>)\n   2958         outflag = True  # happens in more places, so it's easier as default\n   2959         try:\n   2960             try:\n   2961                 self.hooks.pre_run_code_hook()\n   2962                 #rprint('Running code', repr(code_obj)) # dbg\n-> 2963                 exec(code_obj, self.user_global_ns, self.user_ns)\n        code_obj = <code object <module> at 0x7f32c73dd270, file \"<ipython-input-148-1acc040c3d6c>\", line 1>\n        self.user_global_ns = {'BaseEstimator': <class 'sklearn.base.BaseEstimator'>, 'CodeMergeNaff': <class '__main__.CodeMergeNaff'>, 'DecisionTreeClassifier': <class 'sklearn.tree.tree.DecisionTreeClassifier'>, 'GTDFilter': <class '__main__.GTDFilter'>, 'GaussianNB': <class 'sklearn.naive_bayes.GaussianNB'>, 'In': ['', \"get_ipython().run_line_magic('clear', '')\", 'import pandas as pd\\nimport numpy as np', 'from sklearn.preprocessing import LabelEncoder\\nf... import SMOTE\\nfrom scipy.sparse import csr_matrix', 'from sklearn.model_selection import train_test_s...validate, StratifiedKFold, StratifiedShuffleSplit', 'from sklearn.tree import DecisionTreeClassifier\\n...om sklearn.linear_model import LogisticRegression', 'from sklearn.metrics import accuracy_score, precision_score, classification_report, roc_auc_score', \"get_ipython().run_line_magic('env', 'JOBLIB_TEMP_FOLDER=/tmp')\", 'import gc', '# Instead of the excel from their homepage, I us...terrorismdb_0617dist.csv\", encoding=\\'ISO-8859-1\\')', '# In case we want to use a sample\\ngtd_ori = gtd\\ngtd = gtd.sample(frac=0.1)', \"dat = gtd[(gtd.iyear >= 1970) \\n    & (gtd.iyear ...', 'nwound', 'nhostkid', 'gname']]    \\n\\ndat.shape\", 'from sklearn.pipeline import Pipeline\\nfrom sklearn.base import TransformerMixin , BaseEstimator', \"steps_in_val_dict = {\\n    'Set location': [1, 1,..._x', 'train_y', 'val_x', 'val_y')).T\\nsteps_in_val\", 'def showXy(X, y=None):\\n        if isinstance(X, ...\\n            print(\"y.shape: {}\".format(y.shape))', 'class CodeMergeNaff(TransformerMixin, BaseEstima...t(\"CodeMergeNaff transform END\")\\n        return X', 'class ProcPerf(TransformerMixin, BaseEstimator):...lf.y.shape))\\n                \\n        return X, y', 'class GTDFilter(TransformerMixin, BaseEstimator)...                \\n        return X, y #self.y_work', 'class TransWrap(TransformerMixin, BaseEstimator)...format(new_y.shape))\\n\\n        return new_X, new_y', \"crits = {'nkill': (62, 124, 'abc'), \\n         'n... 'def'), \\n         'nhostkid': (400, 800, 'ghi')}\", ...], 'KFold': <class 'sklearn.model_selection._split.KFold'>, 'KNeighborsClassifier': <class 'sklearn.neighbors.classification.KNeighborsClassifier'>, 'LabelEncoder': <class 'sklearn.preprocessing.label.LabelEncoder'>, 'LinearDiscriminantAnalysis': <class 'sklearn.discriminant_analysis.LinearDiscriminantAnalysis'>, ...}\n        self.user_ns = {'BaseEstimator': <class 'sklearn.base.BaseEstimator'>, 'CodeMergeNaff': <class '__main__.CodeMergeNaff'>, 'DecisionTreeClassifier': <class 'sklearn.tree.tree.DecisionTreeClassifier'>, 'GTDFilter': <class '__main__.GTDFilter'>, 'GaussianNB': <class 'sklearn.naive_bayes.GaussianNB'>, 'In': ['', \"get_ipython().run_line_magic('clear', '')\", 'import pandas as pd\\nimport numpy as np', 'from sklearn.preprocessing import LabelEncoder\\nf... import SMOTE\\nfrom scipy.sparse import csr_matrix', 'from sklearn.model_selection import train_test_s...validate, StratifiedKFold, StratifiedShuffleSplit', 'from sklearn.tree import DecisionTreeClassifier\\n...om sklearn.linear_model import LogisticRegression', 'from sklearn.metrics import accuracy_score, precision_score, classification_report, roc_auc_score', \"get_ipython().run_line_magic('env', 'JOBLIB_TEMP_FOLDER=/tmp')\", 'import gc', '# Instead of the excel from their homepage, I us...terrorismdb_0617dist.csv\", encoding=\\'ISO-8859-1\\')', '# In case we want to use a sample\\ngtd_ori = gtd\\ngtd = gtd.sample(frac=0.1)', \"dat = gtd[(gtd.iyear >= 1970) \\n    & (gtd.iyear ...', 'nwound', 'nhostkid', 'gname']]    \\n\\ndat.shape\", 'from sklearn.pipeline import Pipeline\\nfrom sklearn.base import TransformerMixin , BaseEstimator', \"steps_in_val_dict = {\\n    'Set location': [1, 1,..._x', 'train_y', 'val_x', 'val_y')).T\\nsteps_in_val\", 'def showXy(X, y=None):\\n        if isinstance(X, ...\\n            print(\"y.shape: {}\".format(y.shape))', 'class CodeMergeNaff(TransformerMixin, BaseEstima...t(\"CodeMergeNaff transform END\")\\n        return X', 'class ProcPerf(TransformerMixin, BaseEstimator):...lf.y.shape))\\n                \\n        return X, y', 'class GTDFilter(TransformerMixin, BaseEstimator)...                \\n        return X, y #self.y_work', 'class TransWrap(TransformerMixin, BaseEstimator)...format(new_y.shape))\\n\\n        return new_X, new_y', \"crits = {'nkill': (62, 124, 'abc'), \\n         'n... 'def'), \\n         'nhostkid': (400, 800, 'ghi')}\", ...], 'KFold': <class 'sklearn.model_selection._split.KFold'>, 'KNeighborsClassifier': <class 'sklearn.neighbors.classification.KNeighborsClassifier'>, 'LabelEncoder': <class 'sklearn.preprocessing.label.LabelEncoder'>, 'LinearDiscriminantAnalysis': <class 'sklearn.discriminant_analysis.LinearDiscriminantAnalysis'>, ...}\n   2964             finally:\n   2965                 # Reset our crash handler in place\n   2966                 sys.excepthook = old_excepthook\n   2967         except SystemExit as e:\n\n...........................................................................\n/home/andras/Projects/fs-ai/notebook/<ipython-input-148-1acc040c3d6c> in <module>()\n----> 1 cross_val_score(estimator=pipe, X=X, y=y, scoring=scoring, cv=cv, n_jobs=n_jobs)\n\n...........................................................................\n/home/andras/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py in cross_val_score(estimator=Pipeline(memory=None,\n     steps=[('filter', Tra...TC', TransWrap(transformer=None, ytrans=False))]), X=             eventid  iyear  imonth  iday       ...                NaN  \n\n[17035 rows x 134 columns], y=18319                    Nicaraguan Democratic F...o Haram\nName: gname, Length: 17035, dtype: object, groups=None, scoring='accuracy', cv=3, n_jobs=-1, verbose=0, fit_params=None, pre_dispatch='2*n_jobs')\n    337     cv_results = cross_validate(estimator=estimator, X=X, y=y, groups=groups,\n    338                                 scoring={'score': scorer}, cv=cv,\n    339                                 return_train_score=False,\n    340                                 n_jobs=n_jobs, verbose=verbose,\n    341                                 fit_params=fit_params,\n--> 342                                 pre_dispatch=pre_dispatch)\n        pre_dispatch = '2*n_jobs'\n    343     return cv_results['test_score']\n    344 \n    345 \n    346 def _fit_and_score(estimator, X, y, scorer, train, test, verbose,\n\n...........................................................................\n/home/andras/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py in cross_validate(estimator=Pipeline(memory=None,\n     steps=[('filter', Tra...TC', TransWrap(transformer=None, ytrans=False))]), X=             eventid  iyear  imonth  iday       ...                NaN  \n\n[17035 rows x 134 columns], y=18319                    Nicaraguan Democratic F...o Haram\nName: gname, Length: 17035, dtype: object, groups=None, scoring={'score': make_scorer(accuracy_score)}, cv=KFold(n_splits=3, random_state=None, shuffle=False), n_jobs=-1, verbose=0, fit_params=None, pre_dispatch='2*n_jobs', return_train_score=False)\n    201     scores = parallel(\n    202         delayed(_fit_and_score)(\n    203             clone(estimator), X, y, scorers, train, test, verbose, None,\n    204             fit_params, return_train_score=return_train_score,\n    205             return_times=True)\n--> 206         for train, test in cv.split(X, y, groups))\n        cv.split = <bound method _BaseKFold.split of KFold(n_splits=3, random_state=None, shuffle=False)>\n        X =              eventid  iyear  imonth  iday       ...                NaN  \n\n[17035 rows x 134 columns]\n        y = 18319                    Nicaraguan Democratic F...o Haram\nName: gname, Length: 17035, dtype: object\n        groups = None\n    207 \n    208     if return_train_score:\n    209         train_scores, test_scores, fit_times, score_times = zip(*scores)\n    210         train_scores = _aggregate_score_dicts(train_scores)\n\n...........................................................................\n/home/andras/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=-1), iterable=<generator object cross_validate.<locals>.<genexpr>>)\n    784             if pre_dispatch == \"all\" or n_jobs == 1:\n    785                 # The iterable was consumed all at once by the above for loop.\n    786                 # No need to wait for async callbacks to trigger to\n    787                 # consumption.\n    788                 self._iterating = False\n--> 789             self.retrieve()\n        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=-1)>\n    790             # Make sure that we get a last message telling us we are done\n    791             elapsed_time = time.time() - self._start_time\n    792             self._print('Done %3i out of %3i | elapsed: %s finished',\n    793                         (len(self._output), len(self._output),\n\n---------------------------------------------------------------------------\nSub-process traceback:\n---------------------------------------------------------------------------\nAttributeError                                     Fri Aug 17 13:37:31 2018\nPID: 21903                  Python 3.6.6: /home/andras/anaconda3/bin/python\n...........................................................................\n/home/andras/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (Pipeline(memory=None,\n     steps=[('filter', Tra...TC', TransWrap(transformer=None, ytrans=False))]),              eventid  iyear  imonth  iday       ...                NaN  \n\n[17035 rows x 134 columns], 18319                    Nicaraguan Democratic F...o Haram\nName: gname, Length: 17035, dtype: object, {'score': make_scorer(accuracy_score)}, array([ 5679,  5680,  5681, ..., 17032, 17033, 17034]), array([   0,    1,    2, ..., 5676, 5677, 5678]), 0, None, None), {'return_times': True, 'return_train_score': False})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/home/andras/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (Pipeline(memory=None,\n     steps=[('filter', Tra...TC', TransWrap(transformer=None, ytrans=False))]),              eventid  iyear  imonth  iday       ...                NaN  \n\n[17035 rows x 134 columns], 18319                    Nicaraguan Democratic F...o Haram\nName: gname, Length: 17035, dtype: object, {'score': make_scorer(accuracy_score)}, array([ 5679,  5680,  5681, ..., 17032, 17033, 17034]), array([   0,    1,    2, ..., 5676, 5677, 5678]), 0, None, None)\n        kwargs = {'return_times': True, 'return_train_score': False}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/home/andras/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator=Pipeline(memory=None,\n     steps=[('filter', Tra...TC', TransWrap(transformer=None, ytrans=False))]), X=             eventid  iyear  imonth  iday       ...                NaN  \n\n[17035 rows x 134 columns], y=18319                    Nicaraguan Democratic F...o Haram\nName: gname, Length: 17035, dtype: object, scorer={'score': make_scorer(accuracy_score)}, train=array([ 5679,  5680,  5681, ..., 17032, 17033, 17034]), test=array([   0,    1,    2, ..., 5676, 5677, 5678]), verbose=0, parameters=None, fit_params={}, return_train_score=False, return_parameters=False, return_n_test_samples=False, return_times=True, error_score='raise')\n    453 \n    454     try:\n    455         if y_train is None:\n    456             estimator.fit(X_train, **fit_params)\n    457         else:\n--> 458             estimator.fit(X_train, y_train, **fit_params)\n        estimator.fit = <bound method Pipeline.fit of Pipeline(memory=No...C', TransWrap(transformer=None, ytrans=False))])>\n        X_train =              eventid  iyear  imonth  iday       ...                NaN  \n\n[11356 rows x 134 columns]\n        y_train = 61862                                           ...o Haram\nName: gname, Length: 11356, dtype: object\n        fit_params = {}\n    459 \n    460     except Exception as e:\n    461         # Note fit time as time until error\n    462         fit_time = time.time() - start_time\n\n...........................................................................\n/home/andras/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py in fit(self=Pipeline(memory=None,\n     steps=[('filter', Tra...TC', TransWrap(transformer=None, ytrans=False))]), X=             eventid  iyear  imonth  iday       ...                NaN  \n\n[11356 rows x 134 columns], y=61862                                           ...o Haram\nName: gname, Length: 11356, dtype: object, **fit_params={})\n    243         Returns\n    244         -------\n    245         self : Pipeline\n    246             This estimator\n    247         \"\"\"\n--> 248         Xt, fit_params = self._fit(X, y, **fit_params)\n        Xt = undefined\n        fit_params = {}\n        self._fit = <bound method Pipeline._fit of Pipeline(memory=N...C', TransWrap(transformer=None, ytrans=False))])>\n        X =              eventid  iyear  imonth  iday       ...                NaN  \n\n[11356 rows x 134 columns]\n        y = 61862                                           ...o Haram\nName: gname, Length: 11356, dtype: object\n    249         if self._final_estimator is not None:\n    250             self._final_estimator.fit(Xt, y, **fit_params)\n    251         return self\n    252 \n\n...........................................................................\n/home/andras/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py in _fit(self=Pipeline(memory=None,\n     steps=[('filter', Tra...TC', TransWrap(transformer=None, ytrans=False))]), X=             eventid  iyear  imonth  iday       ...                NaN  \n\n[11356 rows x 134 columns], y=61862                                           ...o Haram\nName: gname, Length: 11356, dtype: object, **fit_params={})\n    208                 else:\n    209                     cloned_transformer = clone(transformer)\n    210                 # Fit or load from cache the current transfomer\n    211                 Xt, fitted_transformer = fit_transform_one_cached(\n    212                     cloned_transformer, None, Xt, y,\n--> 213                     **fit_params_steps[name])\n        fit_params_steps = {'DTC': {}, 'filter': {}, 'naffect recoder': {}, 'perfproc': {}}\n        name = 'filter'\n    214                 # Replace the transformer of the step with the fitted\n    215                 # transformer. This is necessary when loading the transformer\n    216                 # from the cache.\n    217                 self.steps[step_idx] = (name, fitted_transformer)\n\n...........................................................................\n/home/andras/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/memory.py in __call__(self=NotMemorizedFunc(func=<function _fit_transform_one at 0x7f32ba29a7b8>), *args=(TransWrap(transformer=None, ytrans=True), None,              eventid  iyear  imonth  iday       ...                NaN  \n\n[11356 rows x 134 columns], 61862                                           ...o Haram\nName: gname, Length: 11356, dtype: object), **kwargs={})\n    357     # Should be a light as possible (for speed)\n    358     def __init__(self, func):\n    359         self.func = func\n    360 \n    361     def __call__(self, *args, **kwargs):\n--> 362         return self.func(*args, **kwargs)\n        self.func = <function _fit_transform_one>\n        args = (TransWrap(transformer=None, ytrans=True), None,              eventid  iyear  imonth  iday       ...                NaN  \n\n[11356 rows x 134 columns], 61862                                           ...o Haram\nName: gname, Length: 11356, dtype: object)\n        kwargs = {}\n    363 \n    364     def call_and_shelve(self, *args, **kwargs):\n    365         return NotMemorizedResult(self.func(*args, **kwargs))\n    366 \n\n...........................................................................\n/home/andras/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py in _fit_transform_one(transformer=TransWrap(transformer=None, ytrans=True), weight=None, X=             eventid  iyear  imonth  iday       ...                NaN  \n\n[11356 rows x 134 columns], y=61862                                           ...o Haram\nName: gname, Length: 11356, dtype: object, **fit_params={})\n    576 \n    577 \n    578 def _fit_transform_one(transformer, weight, X, y,\n    579                        **fit_params):\n    580     if hasattr(transformer, 'fit_transform'):\n--> 581         res = transformer.fit_transform(X, y, **fit_params)\n        res = undefined\n        transformer.fit_transform = <bound method TransformerMixin.fit_transform of TransWrap(transformer=None, ytrans=True)>\n        X =              eventid  iyear  imonth  iday       ...                NaN  \n\n[11356 rows x 134 columns]\n        y = 61862                                           ...o Haram\nName: gname, Length: 11356, dtype: object\n        fit_params = {}\n    582     else:\n    583         res = transformer.fit(X, y, **fit_params).transform(X)\n    584     # if we have a weight for this transformer, multiply output\n    585     if weight is None:\n\n...........................................................................\n/home/andras/anaconda3/lib/python3.6/site-packages/sklearn/base.py in fit_transform(self=TransWrap(transformer=None, ytrans=True), X=             eventid  iyear  imonth  iday       ...                NaN  \n\n[11356 rows x 134 columns], y=61862                                           ...o Haram\nName: gname, Length: 11356, dtype: object, **fit_params={})\n    515         if y is None:\n    516             # fit method of arity 1 (unsupervised transformation)\n    517             return self.fit(X, **fit_params).transform(X)\n    518         else:\n    519             # fit method of arity 2 (supervised transformation)\n--> 520             return self.fit(X, y, **fit_params).transform(X)\n        self.fit = <bound method TransWrap.fit of TransWrap(transformer=None, ytrans=True)>\n        X =              eventid  iyear  imonth  iday       ...                NaN  \n\n[11356 rows x 134 columns]\n        y = 61862                                           ...o Haram\nName: gname, Length: 11356, dtype: object\n        fit_params.transform = undefined\n    521 \n    522 \n    523 class DensityMixin(object):\n    524     \"\"\"Mixin class for all density estimators in scikit-learn.\"\"\"\n\n...........................................................................\n/home/andras/Projects/fs-ai/notebook/<ipython-input-140-a11be80f2199> in fit(self=TransWrap(transformer=None, ytrans=True), X=             eventid  iyear  imonth  iday       ...                NaN  \n\n[11356 rows x 134 columns], y=61862                                           ...o Haram\nName: gname, Length: 11356, dtype: object)\n     20             #print(X.isna().any().any())\n     21             #print(X)\n     22             self.trans.fit(X, self.y)\n     23         else:\n     24             #print(X.isna().any().any())\n---> 25             self.trans.fit(X, y)\n     26         \n     27         return self\n     28 \n     29     def predict(self, X, y=None):\n\nAttributeError: 'NoneType' object has no attribute 'fit'\n___________________________________________________________________________"
     ]
    }
   ],
   "source": [
    "cross_val_score(estimator=pipe, X=X, y=y, scoring=scoring, cv=cv, n_jobs=n_jobs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Manual solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "a6a507613f8522f05fb3451154998fa82657ec65"
   },
   "source": [
    "In the subset there is a slightly different amount of the unique perpetrator groups from what the authors reported (270) (probably due to update in the database?)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "381d9a90172920fb65566c9ba268163ea96ae588"
   },
   "outputs": [],
   "source": [
    "gtd.gname.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "0fe84973909d7ed07ec699f96553c5aacffc4e68"
   },
   "source": [
    "The authors removed those groups which were linked to only one incident. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "d6560d672cf28c3da800400f3d44045d1c6d04c5"
   },
   "outputs": [],
   "source": [
    "dat = dat[dat.gname.isin(dat.gname.value_counts()[dat.gname.value_counts() > 1].index.values)]\n",
    "dat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "c4469f3c6761eabb7bf38a0c4bd635873b0ce5d3"
   },
   "outputs": [],
   "source": [
    "dat = dat.copy()\n",
    "dat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "51cea72b757013e2d19d71e6d46e4757f81ecc78",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dat.loc[:, ['nkill', 'nwound', 'nhostkid']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "80db91a3bb00d1d32a5fa408dfe1e379e0f4f8da"
   },
   "outputs": [],
   "source": [
    "crits = {'nkill': (62, 124, 'abc'), \n",
    "         'nwound': (272, 544, 'def'), \n",
    "         'nhostkid': (400, 800, 'ghi')}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = pd.DataFrame(crits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "crits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "5e0d5a99981f5d94785b4f5ea2bd4370cb96b202"
   },
   "outputs": [],
   "source": [
    "def naff(data, crits):\n",
    "    n = pd.Series('_')\n",
    "    for key, i in zip(crits.keys(), range(len(crits))):\n",
    "        i = data.loc[:, key].copy()\n",
    "\n",
    "        i[data.loc[:,key] == 0] = 'n'\n",
    "        i[(data.loc[:,key] > 0) \n",
    "          & (data.loc[:,key] < crits[key][0])] = crits[key][2][2]\n",
    "        i[(data.loc[:,key] <= crits[key][1]) \n",
    "          & (data.loc[:,key] >= crits[key][0])] = crits[key][2][1]\n",
    "        i[data.loc[:,key] > crits[key][1]] = crits[key][2][0]\n",
    "\n",
    "        n = pd.concat((n, i), axis=1) \n",
    "\n",
    "    return n.drop(columns=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "3391b7e9285119be3092399b98250663fe5bd180",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "naffect = naff(dat, crits)\n",
    "naffect.nhostkid.value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "naf_cri = pd.DataFrame(crits)\n",
    "\n",
    "def ref_naf(data, crits):   \n",
    "    s = pd.DataFrame(data.loc[:, crits.columns.values], copy=True)\n",
    "    print(s.head())\n",
    "\n",
    "    s[data == 0] = 'n'\n",
    "    s[(data > 0) & (data < crits.iloc[0,:])] = crits.iloc[2,:].str[2]\n",
    "    s[(data <= crits.iloc[1,:]) & (data >= crits.iloc[0,:])] = crits.iloc[2,:].str[1]\n",
    "    s[data > crits.iloc[1,:]] = crits.iloc[2,:].str[0]\n",
    "\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "naf_cri.iloc[2,:].str[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "naffect = ref_naf(dat, naf_cri)\n",
    "naffect.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "c41e5ac46bfa6af27034f1c8ea3d99950e4f2edf",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "naffect.nhostkid.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "09a238ec0e29762ed2d31ba8f90deb5460aa5f1b"
   },
   "outputs": [],
   "source": [
    "naffect.nhostkid[naffect.nhostkid == -99] = np.NaN\n",
    "naffect.replace(np.NaN, 'n', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "e8d9a49299afd9cb2fd926f229dc578d61e1a887",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "naffect = naffect.iloc[:,0] +  naffect.iloc[:,1] +  naffect.iloc[:,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "299eba42daffe356fd46f93b0601564abe0ddcfc",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "naffect.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "2bad1f54ed7b2948af1ae8566091ea57df8e6946"
   },
   "outputs": [],
   "source": [
    "dat.drop(columns=['nkill', 'nwound', 'nhostkid'], inplace=True)\n",
    "dat['naffect'] = naffect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "03921aaa47f51b11933e3d188e4dd356f7b16f61"
   },
   "outputs": [],
   "source": [
    "dat.nperps.where(dat.nperps != -99, 0, inplace=True)\n",
    "dat.nperps.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "ae67bdaa97a954b520b0c2d85a87112acb8744c5"
   },
   "outputs": [],
   "source": [
    "dat.isna().any().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "3add66376a534cd73622a2e51c2385adf6d6d1e5"
   },
   "source": [
    "## Defining the column datatypes\n",
    "We try to gain some performance in the forthcoming operations by defining the column datatypes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "ddf5c5d80c790c2d5b1b1d92ca748e09d99fc4ef"
   },
   "outputs": [],
   "source": [
    "dat.info(memory_usage=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "3fbdc42df34c01072f20917d92c55dbfe836e526"
   },
   "outputs": [],
   "source": [
    "dat.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "9592f248e3ba3dfb1c86a0265ba7ea55e65d4edb",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dat.loc[:,['imonth', 'iday', 'extended']] = dat.loc[:,['imonth', 'iday', 'extended']].astype('int8', copy=False)\n",
    "dat.loc[:,['iyear', 'nperps']] = dat.loc[:,['iyear', 'nperps']].astype('int16', copy=False)\n",
    "dat.loc[:,dat.select_dtypes(object).columns.values] = dat.loc[:,dat.select_dtypes(object).columns.values].astype('category', copy=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "b8dbe02c374912e7a654f0cc00bda6fdb28764c6"
   },
   "outputs": [],
   "source": [
    "dat.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "f67a28a2a7551f02c62d059a6a0413760e930d20"
   },
   "outputs": [],
   "source": [
    "dat.info(memory_usage=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "24a59d9f3e44f7396fc25aa03cab4db4ac50b5cd"
   },
   "source": [
    "## Transforming the categoricals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "2ed54736722104c145a22fbf5a5f7dfb57de139b",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dat.gname.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "476b097eb084195ba0d12fb9bc13aa47b747793e",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X = pd.get_dummies(dat.drop(columns='gname'))\n",
    "X = csr_matrix(X)\n",
    "#y = pd.get_dummies(dat.gname)\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(dat.gname)\n",
    "y = y.astype('int16')\n",
    "\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "c8f7f9082329dde2cc40de88723ae420deaff2a9"
   },
   "outputs": [],
   "source": [
    "smote = SMOTE(ratio='all', k_neighbors=1, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "cf26ba85c04370651cbfb4235d1997b9b67924ce"
   },
   "outputs": [],
   "source": [
    "#%%time\n",
    "tXr, tyr = smote.fit_sample(X, y) \n",
    "#tXr, tyr = X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "6ab50acd24605d520b3d5415132932e7bcd64353",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(X.shape)\n",
    "#print(X.nbytes().sum() / 1024)\n",
    "print(tXr.shape)\n",
    "# print(tXr.nbytes / 1024)\n",
    "\n",
    "print(y.shape)\n",
    "print(y.nbytes / 1024)\n",
    "print(tyr.shape)\n",
    "print(tyr.nbytes / 1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "51ff4c191f96aa4a9feedb05c35d81ba28492362",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "np.array([np.unique(y, return_counts=True)[0], np.unique(y, return_counts=True)[1]]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "2c2da6f9d00d36cf7c5b81ae187d6bf64495e0d9",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "np.array([np.unique(tyr, return_counts=True)[0], np.unique(tyr, return_counts=True)[1]]).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "9aaddc8e0e8501c39452e21bc78834990f0cac05"
   },
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "cd062f51c417ffa8e0238426622ebdde19fca480"
   },
   "outputs": [],
   "source": [
    "validation_size = 0.2\n",
    "seed = 17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "c503023a4cbc311c811fad15181a0ac3312fbff9",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train, X_validation, y_train, y_validation = train_test_split(tXr, tyr, test_size=validation_size, random_state=seed)\n",
    "print(X_train.shape)\n",
    "print(X_validation.shape)\n",
    "print(y_train.shape)\n",
    "print(y_validation.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "180ef293b095fde617f6ce9b92c8f227f86f1855"
   },
   "source": [
    "del tXr\n",
    "del tyr\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "781d1e52c5791a20f7bb26b32648b148f4240d14"
   },
   "outputs": [],
   "source": [
    "from sklearn.utils.multiclass import type_of_target\n",
    "type_of_target(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "4f15cac0b3a6ddd2094b6e689bdb84deaa2c5e95"
   },
   "outputs": [],
   "source": [
    "kfold = StratifiedKFold(n_splits=10, random_state=seed)\n",
    "#kfold = KFold(n_splits=10, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "ad4102c91d1716c2ae293cd4aa21f7f0d42988ae"
   },
   "outputs": [],
   "source": [
    "models = {\"Decisiong Tree Classifier\": DecisionTreeClassifier(),\n",
    "          # \"K-Neighbors Classifier\": KNeighborsClassifier(),\n",
    "          # \"Gaussian Naive Bayes\": GaussianNB(),\n",
    "          # \"Linear Discriminant Analysis\": KNeighborsClassifier(),\n",
    "          # \"Logistic Regression\": LogisticRegression(),\n",
    "         }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "e37ca379fad0cb8cf46233624145356175cc310b"
   },
   "outputs": [],
   "source": [
    "def eval_models(models, X, y):\n",
    "    \"\"\"Evaluates selected model's prediction power on the cross-validated training datasets.\n",
    "    Takes\n",
    "        models: Dictionary of \"model_name\": model() pairs.\n",
    "        X: predictor attributes\n",
    "        y: target attribute\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    for model in models:\n",
    "        #print(\"Running {}...\".format(model))\n",
    "        #start = time.time()\n",
    "\n",
    "        result = []\n",
    "        result.append(model)\n",
    "\n",
    "        model_score = cross_validate(models[model],\n",
    "                                    X,\n",
    "                                    y,\n",
    "                                    scoring=['accuracy', # Evaluation metrics\n",
    "                                             'precision_micro',\n",
    "                                             'recall_micro',\n",
    "                                             'f1_micro',\n",
    "                                            # 'roc_auc'\n",
    "                                            ],\n",
    "                                    cv=kfold, # Cross-validation method\n",
    "                                    n_jobs=-1,\n",
    "                                    verbose=0,\n",
    "                                    return_train_score=False)\n",
    "\n",
    "        acc_mean = model_score['test_accuracy'].mean()\n",
    "        acc_std = model_score['test_accuracy'].std()\n",
    "        #auc_mean = model_score['test_roc_auc'].mean()\n",
    "        #auc_std = model_score['test_roc_auc'].std()\n",
    "\n",
    "        print(\"\\n{}:\\n\\tAccuracy: {} ({})\".format(model, acc_mean, acc_std)) #auc_std\n",
    "\n",
    "        #print(\"\\tROC AUC: {} ({})\".format(auc_mean, auc_std))\n",
    "\n",
    "        precision_micro_mean = model_score['test_precision_micro'].mean()\n",
    "        precision_micro_std = model_score['test_precision_micro'].std()\n",
    "        recall_micro_mean = model_score['test_recall_micro'].mean()\n",
    "        recall_micro_std = model_score['test_recall_micro'].std()\n",
    "\n",
    "        f1_micro_mean = model_score['test_f1_micro'].mean()\n",
    "        f1_micro_std = model_score['test_f1_micro'].std()\n",
    "        print(\"\\tF1 micro: {} ({})\".format(f1_micro_mean, f1_micro_std))\n",
    "\n",
    "        #result = result + [acc_mean, acc_std, auc_mean, auc_std]\n",
    "\n",
    "        dur = model_score['fit_time'].sum() + model_score['score_time'].sum()\n",
    "\n",
    "        print(\"\\tduration: {}\\n\".format(dur))\n",
    "        #result.append(dur)\n",
    "\n",
    "        #results.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "1bf18703d8415687025e65d1e6f57f9bcf38ab14",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "% time\n",
    "eval_models(models, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DecisionTreeClassifier().fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprob = model.predict_proba(X_validation)\n",
    "preprob.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(X_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "accuracy_score(y_validation, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprob.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc_score(y_validation, preprob)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
